<div align="center">
  <img src="./image/title.png" width="800" />
</div>

<div align="center">
<strong>github awesome list of recent LLMs and VLMs.ğŸŒâœ¨</strong><br>
<strong>ä¸­æ–‡</strong> | <strong><a href="./README.md">EnglishğŸš€</a></strong><br>
<strong>LLMs</strong> | <strong><a href="./README_VLMs.md">VLMsğŸš€</a></strong>
</div>

## OverView

<div align="center">
  <img src="./image/LLM2023.png"  width="800" />
</div>
<div align="center">
  <img src="./image/LLM2024.png"  width="800" />
</div>
*<em>Image source: <a href="https://lifearchitect.ai/models">LifeArchitect.ai/models</a></em>*


## Quick StartğŸ

æŒ‰å‘å¸ƒæ—¶é—´æ’åºï¼Œ

|    Model     |     Organization      |        Parameters        |                          CheckPoint                          |            Details            |
| :----------: | :-------------------: | :----------------------: | :----------------------------------------------------------: | :---------------------------: |
|   Llama 2    |         Meta          |        7B/13B/70B        | [Llama2 FamilyğŸ¤—](https://huggingface.co/collections/meta-llama/llama-2-family-661da1f90a9d678b6f55773b) |     [Hyperlink](#llama2)      |
|   Llama 3    |         Meta          |          8B/70B          | [Llama3 FamilyğŸ¤—](https://huggingface.co/collections/meta-llama/meta-llama-3-66214712577ca38149ebb2b6) |     [Hyperlink](#llama3)      |
|    Orca2     |       Microsoft       |          7B/13B          | [Orca FamilyğŸ¤—](https://huggingface.co/collections/microsoft/orca-65bbeef1980f5719cccc89a3) |      [Hyperlink](#orca2)      |
|     Qwen     |        Alibaba        | 0.5B/1.8B/4B/7B/14B/72B  |             [QwenğŸ¤—](https://huggingface.co/Qwen)             |         [Hyperlink](#qwen)         |
|   Qwen1.5    |        Alibaba        | 0.5B/1.8B/4B/7B/14B/72B  |           [Qwen1.5ğŸ¤—](https://huggingface.co/Qwen)            |      [Hyperlink](#qwen15)       |
|    Vicuna    |         LMSYS         |        7B/13B/33B        |           [VicunağŸ¤—](https://huggingface.co/lmsys)            |       [Hyperlink](#vicuna)       |
|     XGen     |      Salesforce       |            7B            | [xgen-7b-4k-baseğŸ¤—](https://huggingface.co/Salesforce/xgen-7b-4k-base) |         [Hyperlink](#xgen)         |
|    Falcon    |          UAE          |    1.3B/7.5B/40B/180B    | [Falcon FamilyğŸ¤—](https://huggingface.co/collections/tiiuae/falcon-64fb432660017eeec9837b5a) |       [Hyperlink](#falcon)       |
|     phi      |       Microsoft       |        1B/1.5B/2B        | [phi-1BğŸ¤—](https://huggingface.co/microsoft/phi-1)<br />[phi-1.5BğŸ¤—](https://huggingface.co/microsoft/phi-1_5)<br />[phi-2BğŸ¤—](https://huggingface.co/microsoft/phi-2) |          [Hyperlink](#phi)          |
|     phi3     |       Microsoft       |       3.8B/7B/14B        | [Phi-3 familyğŸ¤— **(only phi-3-mini is available now)**](https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3) |         [Hyperlink](#phi3)         |
|    Gemma     |        Google         |          2B/7B           | [Gemma FamilyğŸ¤—](https://huggingface.co/collections/google/gemma-release-65d5efbccdbb8c4202ec078b) |        [Hyperlink](#gemma)        |
|    Mamba     | Albert Gu and Tri Dao | 130M/370M/790M/1.4B/2.8B |     [state-spacesğŸ¤—](https://huggingface.co/state-spaces)     |        [Hyperlink](#mamba)        |
|    Pythia    |      EleutherAI       |         14Mï½12B         | [Pythia FamilyğŸ¤—](https://huggingface.co/collections/EleutherAI/pythia-scaling-suite-64fb5dfa8c21ebb3db7ad2e1) |       [Hyperlink](pythia)        |
|   Mistral    |      Mistral AI       |            7B            |         [MistralğŸ¤—](https://huggingface.co/mistralai)         |      [Hyperlink](#Mistral)      |
|      YI      |         01-ai         |        6B/9B/34B         | [Yi Family](https://huggingface.co/collections/01-ai/yi-2023-11-663f3f19119ff712e176720f) |           [Hyperlink](#yi)           |
|    YI-1.5    |         01-ai         |        6B/9B/34B         | [Yi-1.5 FamilyğŸ¤—](https://huggingface.co/collections/01-ai/yi-15-2024-05-663f3ecab5f815a3eaca7ca8) |       [Hyperlink](#yi-15)        |
|    Zephyr    |     Hugging Face      |            7B            |   [HuggingFaceH4ğŸ¤— ](https://huggingface.co/HuggingFaceH4)    |       [Hyperlink](#zephyr)       |
| StripedHyena |      Together AI      |            7B            | [StripedHyena FamilyğŸ¤—](https://huggingface.co/collections/togethercomputer/stripedhyena-65d8e6e77540dd1da932dbe1) | [Hyperlink](#stripedHyena) |
|  Persimmon   |     Adept AI Labs     |            8B            | [persimmon-8b-chatğŸ¤—](https://huggingface.co/adept/persimmon-8b-chat) |    [Hyperlink](#persimmon)    |



## Details Regarding Models AboveğŸ“Š

### Llama2

[![arXiv](https://img.shields.io/badge/arXiv-2307.09288-b31b1b.svg)](https://arxiv.org/abs/2307.09288) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/meta-llama/llama)
[![Hugging Face model](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-models-blue)](https://huggingface.co/collections/meta-llama/llama-2-family-661da1f90a9d678b6f55773b)


Llama 2é¢„è®­ç»ƒæ¨¡å‹ç›¸è¾ƒäº Llama 1 æ¨¡å‹æœ‰æ˜¾è‘—æå‡ï¼Œå¢åŠ äº† 40% çš„è®­ç»ƒè¯å…ƒæ€»æ•°ï¼Œå¹¶é‡‡ç”¨äº†æ›´é•¿çš„ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆé«˜è¾¾ 4000 è¯å…ƒï¼‰ï¼ŒåŒæ—¶è¿˜åˆ©ç”¨åˆ†ç»„æŸ¥è¯¢æ³¨æ„åŠ›æœºåˆ¶ï¼Œæå¤§åŠ é€Ÿäº† 70B æ¨¡å‹çš„æ¨ç†é€Ÿåº¦ã€‚Llama 2-Chat ç³»åˆ—æ¨¡å‹é‡‡ç”¨äº†åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰æŠ€æœ¯ï¼Œä¸“é—¨é’ˆå¯¹å¯¹è¯åœºæ™¯è¿›è¡Œä¼˜åŒ–ã€‚åœ¨å¹¿æ³›çš„æœ‰ç”¨æ€§å’Œå®‰å…¨æ€§æµ‹è¯•åŸºå‡†ä¸­ï¼ŒLlama 2-Chat çš„è¡¨ç°è¶…è¿‡äº†å¤šæ•°ç°æœ‰å¼€æ”¾æ¨¡å‹ï¼Œå¹¶ä¸”åœ¨äººç±»è¯„ä¼°ä¸­æ˜¾ç¤ºå‡ºä¸ ChatGPT ç›¸åª²ç¾çš„æ€§èƒ½ã€‚

- **Date:** 2023-07
- **Pretrain Data Scale:** 2T
- **Language Support:** en
- **Parameter Size:** 7B/13B/70B



### Llama3

[![AI Blog](https://img.shields.io/badge/AI%20Blog-Meta%20AI-orange.svg)](https://ai.meta.com/blog/)
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/meta-llama/llama3)
[![Hugging Face model](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-models-blue)](https://huggingface.co/collections/meta-llama/meta-llama-3-66214712577ca38149ebb2b6)

ç›¸è¾ƒäº Llama 2ï¼ŒLlama 3 æœ€æ˜¾è‘—çš„å˜åŒ–åœ¨äºå¼•å…¥äº†ä¸€ä¸ªæ–°çš„ Tokenizerï¼Œå¹¶å°†è¯æ±‡è¡¨çš„è§„æ¨¡æ‰©å±•åˆ°äº† 128,256 ä¸ªè¯æ±‡ï¼ˆå…ˆå‰ç‰ˆæœ¬ä¸º 32,000 ä¸ª Tokenï¼‰ã€‚è¿™æ ·ä¸€ä¸ªæ›´åºå¤§çš„è¯æ±‡è¡¨å¯ä»¥æ›´æœ‰æ•ˆåœ°å¯¹æ–‡æœ¬è¿›è¡Œç¼–ç ï¼Œæ— è®ºæ˜¯è¾“å…¥è¿˜æ˜¯è¾“å‡ºï¼Œä¹Ÿå¯èƒ½å¢å¼ºæ¨¡å‹å¤„ç†å¤šè¯­è¨€çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œè¿™ä¸€æ”¹å˜åŒæ—¶å¯¼è‡´äº†åµŒå…¥å±‚çš„è¾“å…¥å’Œè¾“å‡ºçŸ©é˜µçš„å°ºå¯¸å¢å¤§ï¼Œä»è€Œå¢åŠ äº†å°å‹æ¨¡å‹çš„å‚æ•°é‡ã€‚

- **Date:** 2024-04
- **Pretrain Data Scale:** 1.5T
- **Language Support:** en
- **Parameter Size:** 8B/70B



### Orca2
[![arXiv](https://img.shields.io/badge/arXiv-2311.11045-b31b1b.svg)](https://arxiv.org/pdf/2311.11045.pdf) 
[![Hugging Face collection](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-models-blue)](https://huggingface.co/collections/microsoft/orca-65bbeef1980f5719cccc89a3)


Orca 2 is a finetuned version of LLAMA-2. Orca 2â€™s training data is a synthetic dataset that was created to enhance the small modelâ€™s reasoning abilities. All synthetic training data was moderated using the Microsoft Azure content filters.

è®ºæ–‡ä¸­è¯¦ç»†ä»‹ç»äº†Orca æ˜¯å¦‚ä½•åœ¨è¾ƒå°æ¨¡å‹çš„æƒ…å†µä¸‹ï¼Œä¹Ÿèƒ½åª²ç¾ GPT 3.5 ç”šè‡³ GPT 4 çš„å¤§è¯­è¨€æ¨¡å‹ã€‚

- **Date:** 2023-11
- **Pretrain Data Scale:** same as LLAMA-2
- **Language Support:** en
- **Parameter Size:** 7B/13B



### Qwen

[![arXiv](https://img.shields.io/badge/arXiv-2309.16609-b31b1b.svg)](https://arxiv.org/abs/2309.16609) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/QwenLM/Qwen) 
[![Hugging Face model](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-models-blue)](https://huggingface.co/Qwen)

é€šè¿‡æŒ‡ä»¤å¾®è°ƒï¼ˆInstruction Fine-Tuningï¼‰å¯¹ç‰¹å®šä»»åŠ¡è¿›è¡Œä¼˜åŒ–ï¼Œæ¯”å¦‚ç¼–ç¨‹è¯­è¨€ç”Ÿæˆï¼ˆCodeQwenï¼‰ï¼Œé‡‡ç”¨äº†æ··åˆä¸“å®¶ï¼ˆMixture of Experts, MoEï¼‰å’Œç¨€ç–æ¿€æ´»æŠ€æœ¯.

- **Date:** 2023-08
- **Pretrain Data Scale:** 2.2T~3T(1.8B:2.2T;7B:2.4T;14B:3.0T)
- **Language Support:** en,zh
- **Parameter Size:** 0.5B/1.8B/4B/7B/14B/72B



### Qwen1.5

[![AI Blog](https://img.shields.io/badge/AI%20Blog-QWen%20AI-orange.svg)](https://qwen.readthedocs.io/en/latest/) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/QwenLM/Qwen1.5) 
[![Hugging Face model](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-models-blue)](https://huggingface.co/Qwen)

Qwen1.5çš„å„ä¸ªæ¨¡å‹åœ¨è®­ç»ƒä¸Šä½¿ç”¨äº†æ›´å¤šçš„Tokenï¼Œå¹¶é’ˆå¯¹ç‰¹å®šä»»åŠ¡å¦‚ä»£ç ç”Ÿæˆè¿›è¡Œäº†æŒ‡ä»¤å¾®è°ƒã€‚ä¾‹å¦‚ï¼ŒCodeQwen1.5ä¸“é—¨é’ˆå¯¹ç¼–ç¨‹ä»»åŠ¡è¿›è¡Œäº†ä¼˜åŒ–ï¼Œé¢„è®­ç»ƒäº†å¤§çº¦3ä¸‡äº¿ä¸ªä¸ä»£ç ç›¸å…³çš„æ•°æ®Tokenã€‚

- **Date:** 2023-02
- **Pretrain Data Scale:** 3T
- **Language Support:** en,zh
- **Parameter Size:** 0.5B/1.8B/4B/7B/14B/72B



### Vicuna

[![AI Blog](https://img.shields.io/badge/AI%20Blog-Vicuna%20AI-orange.svg)](https://lmsys.org/blog/2023-03-30-vicuna/) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/lm-sys/FastChat) 
[![Hugging Face model](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-models-blue)](https://huggingface.co/lmsys)

1. **å†…å­˜ä¼˜åŒ–**ï¼šä¸ºåº”å¯¹Vicunaåœ¨å¤„ç†é•¿ä¸Šä¸‹æ–‡æ—¶çš„éœ€æ±‚ï¼Œå…¶æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦ä»Alpacaçš„512å¢è‡³2048ï¼Œè¿™æ˜¾è‘—æé«˜äº†å¯¹GPUå†…å­˜çš„éœ€æ±‚ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œç ”ç©¶äººå‘˜é‡‡ç”¨äº†æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆgradient checkpointingï¼‰ä¸FlashAttentionæŠ€æœ¯æ¥å‡è½»å†…å­˜å‹åŠ›ã€‚
2. **å¤šè½®å¯¹è¯**ï¼šé€šè¿‡è°ƒæ•´è®­ç»ƒæŸå¤±ä»¥é€‚åº”å¤šè½®å¯¹è¯çš„éœ€æ±‚ï¼Œè®­ç»ƒæŸå¤±çš„è®¡ç®—ä»…åŸºäºèŠå¤©æœºå™¨äººçš„è¾“å‡ºè¿›è¡Œã€‚
3. **é€šè¿‡Spotå®ä¾‹é™ä½æˆæœ¬**ï¼šæ•°æ®é›†è§„æ¨¡å¢å¤§40å€åŠåºåˆ—é•¿åº¦å¢åŠ 4å€ï¼Œå¯¹è®­ç»ƒæå‡ºäº†æ›´å¤§çš„æŒ‘æˆ˜ã€‚ä¸ºé™ä½æˆæœ¬ï¼Œç ”ç©¶äººå‘˜é€šè¿‡SkyPilotæ‰˜ç®¡çš„Spotå®ä¾‹ï¼Œåˆ©ç”¨æŠ¢å è‡ªåŠ¨æ¢å¤å’Œè‡ªåŠ¨åŒºåŸŸåˆ‡æ¢åŠŸèƒ½ï¼Œä½¿ç”¨æˆæœ¬æ›´ä½çš„Spotå®ä¾‹ã€‚è¿™ç§ç­–ç•¥å°†7Bæ¨¡å‹çš„è®­ç»ƒæˆæœ¬ä»500ç¾å…ƒé™è‡³çº¦140ç¾å…ƒï¼Œ13Bæ¨¡å‹çš„è®­ç»ƒæˆæœ¬ä»å¤§çº¦1000ç¾å…ƒé™è‡³300ç¾å…ƒã€‚

- **Date:** 2023-03
- **Pretrain Data Scale:** 1.4T
- **Language Support:** en,zh
- **Parameter Size:** 7B/13B/33B



### XGen

[![arXiv](https://img.shields.io/badge/arXiv-2309.03450-b31b1b.svg)](https://arxiv.org/abs/2309.03450) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/salesforce/xGen) 
[![Hugging Face model](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-models-blue)](https://huggingface.co/Salesforce/xgen-7b-4k-base)

XGen-7Bæ¨¡å‹åœ¨æ”¯æŒé•¿è¾¾8Kä»¤ç‰Œçš„è¾“å…¥ï¼Œé€šè¿‡ä½¿ç”¨æ ‡å‡†å¯†é›†æ³¨æ„åŠ›è¿›è¡Œè®­ç»ƒï¼Œä»¥åŠåœ¨é«˜è¾¾1.5Tä»¤ç‰Œçš„æƒ…å†µä¸‹è¿›è¡Œè®­ç»ƒï¼ŒåŒæ—¶åœ¨å…¬å…±é¢†åŸŸçš„æ•™å­¦æ•°æ®ä¸Šè¿›è¡Œå¾®è°ƒï¼Œå¯ä½œä¸ºä¸€ç§é€šç”¨æ¨¡å‹ï¼Œé€‚ç”¨äºæ ‡å‡†å¤§å°çš„GPUå’Œç§»åŠ¨è®¾å¤‡ã€‚

- **Date:** 2023-07
- **Pretrain Data Scale:** 1.37T
- **Language Support:** en
- **Parameter Size:** 7B



### Falcon

[![AI Blog](https://img.shields.io/badge/AI%20Blog-Falcon%20AI-orange.svg)](https://huggingface.co/blog/falcon-180b) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/falconry/falcon) 
[![Hugging Face model](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-models-blue)](https://huggingface.co/tiiuae)

å¤§é‡è®­ç»ƒæ•°æ®æ¥è‡ª [RefinedWeb](https://arxiv.org/abs/2306.01116) â€”â€” ä¸€ä¸ªæ–°çš„åŸºäº CommonCrawl çš„ç½‘ç»œæ•°æ®é›†ã€‚ä½¿ç”¨äº† [**å¤šæŸ¥è¯¢æ³¨æ„åŠ› (multiquery attention)**](https://arxiv.org/abs/1911.02150)ã€‚åŸå§‹å¤šå¤´ (head) æ³¨æ„åŠ›æ–¹æ¡ˆæ¯ä¸ªå¤´éƒ½åˆ†åˆ«æœ‰ä¸€ä¸ªæŸ¥è¯¢ (query) ã€é”® (key) ä»¥åŠå€¼ (value)ï¼Œè€Œå¤šæŸ¥è¯¢æ³¨æ„åŠ›æ–¹æ¡ˆæ”¹ä¸ºåœ¨æ‰€æœ‰å¤´ä¸Šå…±äº«åŒä¸€ä¸ªé”®å’Œå€¼ã€‚è¿™ä¸ªæŠ€å·§å¯¹é¢„è®­ç»ƒå½±å“ä¸å¤§ï¼Œä½†å®ƒæå¤§åœ° [æé«˜äº†æ¨ç†çš„å¯æ‰©å±•æ€§](https://arxiv.org/abs/2211.05102): äº‹å®ä¸Šï¼Œ **è¯¥æŠ€å·§å¤§å¤§å‡å°‘äº†è‡ªå›å½’è§£ç æœŸé—´ K,V ç¼“å­˜çš„å†…å­˜å ç”¨ï¼Œå°†å…¶å‡å°‘äº† 10-100 å€** (å…·ä½“æ•°å€¼å–å†³äºæ¨¡å‹æ¶æ„çš„é…ç½®)ï¼Œè¿™å¤§å¤§é™ä½äº†æ¨¡å‹æ¨ç†çš„å†…å­˜å¼€é”€ã€‚è€Œå†…å­˜å¼€é”€çš„å‡å°‘ä¸ºè§£é”æ–°çš„ä¼˜åŒ–å¸¦æ¥äº†å¯èƒ½ï¼Œå¦‚çœä¸‹æ¥çš„å†…å­˜å¯ä»¥ç”¨æ¥å­˜å‚¨å†å²å¯¹è¯ï¼Œä»è€Œä½¿å¾—æœ‰çŠ¶æ€æ¨ç†æˆä¸ºå¯èƒ½ã€‚

- **Date:** 2023-07
- **Pretrain Data Scale:** 2T
- **Language Support:** en,fr
- **Parameter Size:** 1.3B/7.5B/40B/180B



### Phi

[![AI Blog](https://img.shields.io/badge/AI%20Blog-Phi%20AI-orange.svg)](https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/microsoft/dstoolkit-phi2-finetune) 
[![Hugging Face model](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-models-blue)](https://huggingface.co/microsoft/phi-2)

**è®­ç»ƒæ•°æ®è´¨é‡ï¼š** åˆ©ç”¨â€œæ•™ç§‘ä¹¦è´¨é‡â€çš„æ•°æ®ï¼Œä¸“æ³¨äºæ—¨åœ¨ä¼ æˆå¸¸è¯†æ¨ç†å’Œå¸¸è¯†çš„åˆæˆæ•°æ®é›†ã€‚åŸ¹è®­è¯­æ–™åº“é€šè¿‡ç²¾å¿ƒæŒ‘é€‰çš„ç½‘ç»œæ•°æ®è¿›è¡Œæ‰©å……ï¼Œå¹¶æ ¹æ®æ•™è‚²ä»·å€¼å’Œå†…å®¹è´¨é‡è¿›è¡Œè¿‡æ»¤ã€‚ï¼ˆPhi-2 leverages â€œtextbook-qualityâ€ data, focusing on synthetic datasets designed to impart common sense reasoning and general knowledge. The training corpus is augmented with carefully selected web data, filtered based on educational value and content quality.ï¼‰

**åˆ›æ–°çš„ç¼©æ”¾æŠ€æœ¯ï¼š** å¾®è½¯åœ¨å¼€å‘ Phi-2 æ—¶ï¼Œé‡‡ç”¨äº†ä»å…¶å‰ä»£æ¨¡å‹ Phi-1.5 åˆ° Phi-2 çš„çŸ¥è¯†æ‰©å±•æŠ€æœ¯ã€‚ä»–ä»¬åˆ©ç”¨äº† Phi-1.5 æ¨¡å‹ä¸­å·²æœ‰çš„çŸ¥è¯†å’Œå­¦ä¹ æˆæœï¼Œå°†è¿™äº›çŸ¥è¯†è½¬ç§»åˆ°æ–°æ¨¡å‹ä¸­ï¼Œä»è€ŒåŠ é€Ÿäº†æ–°æ¨¡å‹è®­ç»ƒçš„æ”¶æ•›é€Ÿåº¦ã€‚ç®€å•æ¥è¯´ï¼Œå°±æ˜¯è®©æ–°æ¨¡å‹åœ¨å­¦ä¹ åˆæœŸå°±èƒ½ç«™åœ¨ä¸€ä¸ªæ›´é«˜çš„èµ·ç‚¹ä¸Šï¼Œå¿«é€Ÿè¾¾åˆ°é«˜æ€§èƒ½ã€‚è¿™ç§çŸ¥è¯†è½¬ç§»çš„æ–¹æ³•ä¸ä»…æé«˜äº†è®­ç»ƒæ•ˆç‡ï¼Œè¿˜æ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨å„ç§åŸºå‡†æµ‹è¯•ä¸­çš„å¾—åˆ†ã€‚

**ä¼˜åŒ–çš„Transformerç»“æ„**ï¼šPhi-2ç ”ç©¶äººå‘˜å¼•å…¥äº†è‡ªå®šä¹‰ä¼˜åŒ–ä»¥æœ€å¤§é™åº¦åœ°æé«˜æ•ˆç‡ã€‚

- **Date:** 2023-12
- **Pretrain Data Scale:** 1.4T
- **Language Support:** en
- **Parameter Size:** 1B/1.5B/2B



### Phi3

[![arXiv](https://img.shields.io/badge/arXiv-2404.14219-b31b1b.svg)](https://arxiv.org/abs/2404.14219) 
[![Hugging Face model](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-models-blue)](https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3)

é‡‡ç”¨äº†transformer decoderæ¶æ„ï¼Œå…¶é»˜è®¤çš„ä¸Šä¸‹æ–‡é•¿åº¦ä¸º**4K token**ã€‚å›¢é˜Ÿè¿˜é€šè¿‡LongRopeæŠ€æœ¯æ¨å‡ºäº†é•¿ä¸Šä¸‹æ–‡ç‰ˆæœ¬ï¼Œå°†ä¸Šä¸‹æ–‡é•¿åº¦æ‰©å±•åˆ°**128K token**ã€‚ç”±äºä½“ç§¯å°å·§ï¼Œphi-3-miniæ¨¡å‹å¯ä»¥è¢«é‡åŒ–ä¸º**4 bit**ï¼Œä½¿å…¶å†…å­˜å ç”¨ä»…çº¦ä¸º**1.8GB**ã€‚å›¢é˜Ÿé€šè¿‡åœ¨é…å¤‡A16ä»¿ç”ŸèŠ¯ç‰‡çš„iPhone 14ä¸Šéƒ¨ç½²phi-3-miniè¿›è¡Œäº†æµ‹è¯•ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿåœ¨å®Œå…¨ç¦»çº¿çš„çŠ¶æ€ä¸‹åŸç”Ÿè¿è¡Œï¼Œå¹¶å®ç°äº†æ¯ç§’å¤„ç†è¶…è¿‡12ä¸ªtokensçš„é€Ÿåº¦ã€‚

è®­ç»ƒæ•°æ®é›†ä¹Ÿæ˜¯åˆ›æ–°ç‚¹ä¹‹ä¸€ï¼ŒåŒ…æ‹¬ç»è¿‡ä¸¥æ ¼è¿‡æ»¤çš„ç½‘ç»œæ•°æ®å’Œåˆæˆæ•°æ®ï¼Œè¿™äº›æ•°æ®ç»è¿‡ç²¾å¿ƒç­›é€‰å’Œä¼˜åŒ–ï¼Œä½¿ç ”ç©¶äººå‘˜èƒ½å¤Ÿæ˜¾è‘—å‡å°æ¨¡å‹çš„å¤§å°è€Œä¸å½±å“æ€§èƒ½ã€‚

- **Date:** 2024-04
- **Pretrain Data Scale:** 3.3Tï½4.8T
- **Language Support:** en
- **Parameter Size:** 3.8B/7B/14B



### Gemma

[![AI Blog](https://img.shields.io/badge/AI%20Blog-Phi%20AI-orange.svg)](https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/google-deepmind/gemma) 
[![Hugging Face model](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-models-blue)](https://huggingface.co/collections/google/gemma-release-65d5efbccdbb8c4202ec078b)

å¯åœ¨å„ç±»æ¶ˆè´¹çº§ç¡¬ä»¶ä¸Šè¿è¡Œï¼Œæ— éœ€æ•°æ®é‡åŒ–å¤„ç†ï¼Œæ‹¥æœ‰é«˜è¾¾ 8K tokens çš„å¤„ç†èƒ½åŠ›ï¼Œåœ¨ 7B å‚æ•°çº§åˆ«Gemma è¡¨ç°å‡ºè‰²ï¼Œæ¯”åŒå‚æ•°çº§åˆ«çš„Llama2æ€§èƒ½è¦å¥½ä¸€äº›ã€‚ä¸ Google Cloud é›†æˆï¼Œå¯ä»¥é€šè¿‡ Vertex AI æˆ– Google Kubernetes Engine (GKE) åœ¨ Google Cloud ä¸Šéƒ¨ç½²å’Œè®­ç»ƒ Gemmaã€‚

- **Date:** 2024-02
- **Pretrain Data Scale:** 2T
- **Language Support:** en
- **Parameter Size:** 2B/7B



### Mamba

[![arXiv](https://img.shields.io/badge/arXiv-2312.00752-b31b1b.svg)](https://arxiv.org/abs/2312.00752) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/state-spaces/mamba) 
[![Hugging Face model](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-models-blue)](https://huggingface.co/state-spaces)
- **Date:** 2023-12
- **Pretrain Data Scale:** 10B
- **Language Support:** en
- **Parameter Size:** 130M/370M/790M/1.4B/2.8B

Mamba 2.8B æ˜¯ä¸€ç§åŸºäºçŠ¶æ€ç©ºé—´æ¨¡å‹æ¶æ„çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œåœ¨å¤„ç†ä¿¡æ¯å¯†é›†å‹æ•°æ®ï¼ˆå¦‚è¯­è¨€å»ºæ¨¡ï¼‰æ–¹é¢å¯ä»¥å’Œä¼ ç»Ÿçš„ Transformer æ¨¡å‹ç«äº‰ã€‚

ä¸»è¦åˆ›æ–°ç‚¹å¦‚ä¸‹

1. **é€‰æ‹©æ€§çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMsï¼‰**ï¼šMamba é€šè¿‡åŸºäºè¾“å…¥å‚æ•°åŒ– SSM å‚æ•°å¼•å…¥äº†é€‰æ‹©æœºåˆ¶ã€‚è¿™ä½¿å¾—æ¨¡å‹å¯ä»¥æ ¹æ®å½“å‰ä»¤ç‰Œæ²¿åºåˆ—é•¿åº¦ç»´åº¦é€‰æ‹©æ€§åœ°ä¼ æ’­æˆ–é—å¿˜ä¿¡æ¯ï¼Œå¢å¼ºäº†å…¶èšç„¦ç›¸å…³ä¿¡æ¯åŒæ—¶ä¸¢å¼ƒæ— å…³æ•°æ®çš„èƒ½åŠ›ã€‚

2. **ç¡¬ä»¶æ„ŸçŸ¥å¹¶è¡Œç®—æ³•ï¼š** ä¸ºäº†å…‹æœé€‰æ‹©æ€§çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMsï¼‰å¸¦æ¥çš„è®¡ç®—å¤æ‚æ€§ï¼ŒMamba é‡‡ç”¨äº†ä¸€ç§ç¡¬ä»¶æ„ŸçŸ¥ç®—æ³•ï¼Œä½¿ç”¨æ‰«æè€Œéå·ç§¯æ¥è®¡ç®—æ¨¡å‹

   > æ‰«ææ“ä½œåœ¨é€’å½’è®¡ç®—ä¸­æ›´å¸¸è§ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†éœ€è¦æ ¹æ®è¾“å…¥åŠ¨æ€è°ƒæ•´å‚æ•°çš„æ¨¡å‹æ—¶ï¼Œåœ¨ Mamba æ¨¡å‹ä¸­ï¼Œç”±äºå¼•å…¥äº†é€‰æ‹©æ€§æœºåˆ¶ï¼Œä½¿å¾—æ¨¡å‹çš„å‚æ•°å¯ä»¥æ ¹æ®è¾“å…¥åŠ¨æ€å˜åŒ–ï¼Œè¿™ç ´åäº†å·ç§¯çš„ä½¿ç”¨æ¡ä»¶ã€‚æ‰«ææ“ä½œæŒ‰ç…§åºåˆ—çš„é¡ºåºï¼Œä¸€æ­¥æ­¥åœ°è®¡ç®—åºåˆ—çš„çŠ¶æ€ï¼Œå…è®¸æ¯ä¸€æ­¥çš„è®¡ç®—éƒ½å¯ä»¥åŸºäºå½“å‰çš„è¾“å…¥å’Œå‰ä¸€çŠ¶æ€åŠ¨æ€è°ƒæ•´ã€‚

3. **é•¿ä¸Šä¸‹æ–‡å¤„ç†**ï¼šå¯ä»¥è¾¾åˆ°100ä¸‡åºåˆ—é•¿åº¦ï¼Œåœ¨éŸ³é¢‘å¤„ç†å’ŒåŸºå› ç»„å­¦æ–¹é¢æ€§èƒ½è‰¯å¥½





### Pythia
[![arXiv](https://img.shields.io/badge/arXiv-2304.01373-b31b1b.svg)](https://arxiv.org/abs/2304.01373) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/EleutherAI/pythia) 
[![Hugging Face model](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-models-blue)](https://huggingface.co/collections/EleutherAI/pythia-scaling-suite-64fb5dfa8c21ebb3db7ad2e1)
- **Date:** 2023-04
- **Pretrain Data Scale:** 10B
- **Language Support:** en
- **Parameter Size:** 130M/370M/790M/1.4B/2.8B


Pythia *Scaling Suite*æ˜¯ä¸ºä¿ƒè¿›å¯è§£é‡Šæ€§ç ”ç©¶è€Œå¼€å‘çš„æ¨¡å‹é›†åˆï¼Œis a suite of 16 LLMs all trained on public data seen in the exact same order and ranging in size from 70M to 12B parameters.

> å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¥—ä»¶ï¼Œæ˜¯ä¸€ç³»åˆ—ç”¨äºç§‘å­¦ç ”ç©¶çš„è¯­è¨€æ¨¡å‹çš„é›†åˆã€‚è¿™äº›æ¨¡å‹åœ¨è®¾è®¡å’Œå®ç°æ—¶æ³¨é‡ä¸€è‡´æ€§å’Œå¯é‡ç°æ€§ï¼Œç›®çš„æ˜¯è®©ç ”ç©¶è€…èƒ½å¤Ÿæ·±å…¥åˆ†æå’Œç†è§£å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è®­ç»ƒå’Œæ‰©å±•è¿‡ç¨‹ä¸­çš„è¡¨ç°å’Œå˜åŒ–ã€‚

Pythia contains two sets of eight models of sizes 70M, 160M, 410M, 1B, 1.4B, 2.8B, 6.9B, and 12B. For each size, there are two models: one trained on the Pile, and one trained on the Pile after the dataset has been globally deduplicated. All 8 model sizes are trained on the exact same data, in the exact same order. 

> Pile æ˜¯ä¸€ä¸ªå¤§å‹çš„ã€å¼€æºçš„è‹±æ–‡æ–‡æœ¬æ•°æ®é›†ï¼Œä¸“ä¸ºè®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹è€Œè®¾è®¡ã€‚å®ƒç”± 22 ä¸ªä¸åŒçš„ã€é«˜è´¨é‡çš„å­æ•°æ®é›†ç»„æˆï¼Œè¿™äº›å­æ•°æ®é›†åŒ…æ‹¬äº†ä»ä¹¦ç±ã€å­¦æœ¯è®ºæ–‡ã€æ³•å¾‹æ–‡çŒ®ã€åœ¨çº¿é—®ç­”ï¼Œåˆ°ç¼–ç¨‹ä»£ç å’Œç”µå½±å­—å¹•ç­‰å¤šç§ç±»å‹çš„æ–‡æœ¬ã€‚è¢«å¹¿æ³›ç”¨äºè®­ç»ƒåŒ…æ‹¬è‡ªå›å½’å˜æ¢å™¨åœ¨å†…çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œè¯¦æƒ…ï¼š[click here](https://pile.eleuther.ai/)ã€‚

Pythiaå¥—ä»¶æ˜¯å”¯ä¸€ä¸€ä¸ªæ»¡è¶³ä»¥ä¸‹ä¸‰ä¸ªå…³é”®ç‰¹æ€§çš„å…¬å¼€å‘å¸ƒçš„LLMå¥—ä»¶ï¼š

1. æ¨¡å‹è¦†ç›–äº†å¤šä¸ªæ•°é‡çº§çš„æ¨¡å‹è§„æ¨¡ã€‚
2. æ‰€æœ‰æ¨¡å‹éƒ½æŒ‰ç…§ç›¸åŒçš„é¡ºåºåœ¨ç›¸åŒçš„æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒã€‚
3. æ•°æ®å’Œä¸­é—´æ£€æŸ¥ç‚¹å¯ä¾›å…¬å¼€ç ”ç©¶ä½¿ç”¨ã€‚

ä½œè€…è¿˜è¿›è¡Œäº†ä¸‰ä¸ªè¯­è¨€å»ºæ¨¡ç ”ç©¶çš„æ¡ˆä¾‹ç ”ç©¶

1. **æ•°æ®åè§å¦‚ä½•å½±å“å­¦ä¹ è¡Œä¸º**ï¼šç ”ç©¶è¡¨æ˜ï¼Œé€šè¿‡å¯¹è¯­è¨€æ¨¡å‹çš„é€‚å½“å¹²é¢„ï¼Œå¯ä»¥å‘ç°æ•°æ®ä¸­ä»£è¯çš„å‡ºç°é¢‘ç‡ä¼šå½±å“æ¨¡å‹çš„å­¦ä¹ åå·®ã€‚ç ”ç©¶ä¹Ÿæå‡ºä¸€ç§å¯æ§çš„æ–¹æ³•æ¥åˆ†æå’Œå‡è½»æ¨¡å‹çš„åå·®é—®é¢˜ã€‚
2. **è®­ç»ƒé¡ºåºæ˜¯å¦å½±å“è®°å¿†**ï¼šç ”ç©¶è€…å‘ç°ï¼Œæ³Šæ¾æ¨¡å‹èƒ½å¤Ÿå¾ˆå¥½åœ°é€‚é…æ•°æ®ï¼Œè¿™è¯´æ˜è®­ç»ƒé¡ºåºå¯¹äºè®°å¿†çš„å½±å“è¾ƒå°ã€‚è¯¥æ¨¡å‹è¡¨æ˜ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹çš„å¼€å§‹æˆ–ç»“æŸé˜¶æ®µï¼Œè®°å¿†åºåˆ—å¹¶ä¸ä¼šæ›´å¯†é›†åœ°å‡ºç°ï¼Œè€Œæ˜¯åœ¨å„ä¸ªæ£€æŸ¥ç‚¹ä¹‹é—´ï¼Œå¯ä»¥è§‚å¯Ÿåˆ°å¤§è‡´ç›¸åŒæ•°é‡çš„è®°å¿†åºåˆ—åˆ†å¸ƒã€‚
3. **é¢„è®­ç»ƒæœ¯è¯­é¢‘ç‡æ˜¯å¦å½±å“æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­çš„ä»»åŠ¡æ€§èƒ½**ï¼šè¿™ç§ç›¸å…³æ€§åœ¨è¾ƒå¤§çš„æ¨¡å‹ä¸­è¡¨ç°å¾—æ›´ä¸ºæ˜æ˜¾ã€‚è¾ƒå°çš„æ¨¡å‹å³ä¾¿åœ¨è®­ç»ƒçš„åæœŸé˜¶æ®µä¹Ÿå¾ˆéš¾åœ¨è¿™äº›ä»»åŠ¡ä¸Šå–å¾—å‡†ç¡®çš„ç»“æœï¼Œè¡¨æ˜è¿™äº›æ¨¡å‹æ— è®ºè®­ç»ƒæ•°æ®ä¸­ç›¸å…³ä¿¡æ¯çš„é¢‘ç‡å¦‚ä½•ï¼Œéƒ½æ— æ³•æˆåŠŸå­¦ä¹ è¿™äº›ä»»åŠ¡ã€‚





### Mistral
[![arXiv](https://img.shields.io/badge/arXiv-2310.06825-b31b1b.svg)](https://arxiv.org/abs/2310.06825) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/mistralai/mistral-common) 
[![Hugging Face model](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-models-blue)](https://huggingface.co/mistralai)

- **Date:** 2023-09
- **Pretrain Data Scale:** 8T
- **Language Support:** en
- **Parameter Size:** 7B

Mistral 7B è¶…è¶Šäº†ä»¥å‰æœ€å¥½çš„ 130 äº¿å‚æ•°æ¨¡å‹ï¼ˆLlama 2ï¼‰åœ¨æ‰€æœ‰è¯„æµ‹åŸºå‡†ä¸Šçš„è¡¨ç°ï¼Œå¹¶ä¸”åœ¨æ¨ç†ã€æ•°å­¦å’Œä»£ç ç”Ÿæˆæ–¹é¢è¶…è¿‡äº†æœ€å¥½çš„ 340 äº¿å‚æ•°æ¨¡å‹ï¼ˆLlama 1ï¼‰ï¼Œåˆ©ç”¨åˆ†ç»„æŸ¥è¯¢æ³¨æ„åŠ›ï¼ˆGrouped-query Attention, GQAï¼‰å’Œæ»‘åŠ¨çª—å£æ³¨æ„åŠ›ï¼ˆSliding Window Attention, SWAï¼‰ã€‚GQA æ˜¾è‘—æé«˜äº†æ¨ç†é€Ÿåº¦ï¼Œå‡å°‘äº†è§£ç æ—¶çš„å†…å­˜éœ€æ±‚ã€‚SWA èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å¤„ç†æ›´é•¿çš„åºåˆ—ï¼Œä»è€Œé™ä½è®¡ç®—æˆæœ¬ã€‚

Mistral-7B is a decoder-only Transformer with the following architectural choices:

- Sliding Window Attention - Trained with 8k context length and fixed cache size, with a theoretical attention span of 128K tokens
- GQA (Grouped Query Attention) - allowing faster inference and lower cache size.
- Byte-fallback BPE tokenizer - ensures that characters are never mapped to out of vocabulary tokens.



### YI
[![arXiv](https://img.shields.io/badge/arXiv-2403.04652-b31b1b.svg)](https://arxiv.org/abs/2403.04652) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/01-ai/Yi) 
[![Hugging Face collections](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-collections-blue)](https://huggingface.co/collections/01-ai/yi-2023-11-663f3f19119ff712e176720f)

- **Date:** 2023-11
- **Pretrain Data Scale:**0. 8Tï½3T
- **Language Support:** Multiple
- **Parameter Size:** 6B/9B/34B

Yiç³»åˆ—åŒ…æ‹¬6Bã€9Bå’Œ34Bå‚æ•°è§„æ¨¡çš„åŸºç¡€æ¨¡å‹ï¼Œæ¯ä¸ªæ¨¡å‹çš„é»˜è®¤ä¸Šä¸‹æ–‡çª—å£ä¸º4Kï¼Œå¹¶åœ¨æ¨ç†æ—¶å¯ä»¥æ‰©å±•åˆ°32Kã€‚

æ ¸å¿ƒäº®ç‚¹æœ‰ä»¥ä¸‹å‡ æ–¹é¢

1. **é«˜è´¨é‡æ•°æ®é¢„å¤„ç†**ï¼šYiç³»åˆ—æ¨¡å‹ä½¿ç”¨äº†ä¸¥æ ¼çš„æ¸…æ´—ç®¡é“æ¥ç¡®ä¿é«˜è´¨é‡çš„è®­ç»ƒæ•°æ®ã€‚è¿™åŒ…æ‹¬ä½¿ç”¨å¯å‘å¼è§„åˆ™å’Œå­¦ä¹ è¿‡æ»¤å™¨æ¥å»é™¤ä½è´¨é‡å’Œä¸é€‚å½“çš„å†…å®¹ï¼Œç¡®ä¿æ•°æ®é›†çš„çº¯å‡€åº¦å’Œç›¸å…³æ€§ã€‚
2. **æ”¹è¿›çš„æ³¨æ„åŠ›æœºåˆ¶**ï¼šYiæ¨¡å‹é‡‡ç”¨äº†æ”¹è¿›çš„Grouped-Query Attentionï¼ˆGQAï¼‰æœºåˆ¶ï¼Œè¿™å¤§å¤§å‡å°‘äº†è®­ç»ƒå’Œæ¨ç†çš„æˆæœ¬ï¼Œä¸ä¼ ç»Ÿçš„å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ç›¸æ¯”å…·æœ‰æ›´é«˜çš„æ•ˆç‡ã€‚
3. **å¤šæ¨¡æ€æ”¯æŒ**ï¼šYiç³»åˆ—è¿˜åŒ…æ‹¬å¤šæ¨¡æ€æ¨¡å‹ï¼ˆYi-VLï¼‰ï¼Œè¿™äº›æ¨¡å‹èƒ½å¤Ÿå¤„ç†æ–‡æœ¬å’Œå›¾åƒè¾“å…¥ï¼Œè¿›è¡Œå¤šè½®å¯¹è¯å’Œè§†è§‰é—®ç­”ã€‚
4. **å¯¹ä¸­æ–‡æ”¯æŒæ›´å¥½**ï¼šå¯¹æ ‡chatGPT4åœ¨CMMLUã€E-Evalã€Gaokao ä¸‰ä¸ªä¸»è¦çš„ä¸­æ–‡æŒ‡æ ‡ä¸ŠYi-34Bè¡¨ç°å¾—å¾ˆå¥½ã€‚

> Grouped-Query Attention (GQA) æœºåˆ¶çš„åŸç†ï¼šä¼ ç»Ÿçš„å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ä¸­ï¼Œæ¯ä¸ªæ³¨æ„åŠ›å¤´éƒ½æœ‰è‡ªå·±ç‹¬ç«‹çš„æŸ¥è¯¢ï¼ˆQï¼‰ã€é”®ï¼ˆKï¼‰å’Œå€¼ï¼ˆVï¼‰å‘é‡ã€‚åœ¨GQAä¸­ï¼ŒæŸ¥è¯¢å¤´è¢«åˆ†æˆè‹¥å¹²ç»„ï¼Œæ¯ç»„å…±äº«ä¸€ä¸ªé”®ï¼ˆKï¼‰å’Œä¸€ä¸ªå€¼ï¼ˆVï¼‰å‘é‡ã€‚å…·ä½“æ¥è¯´ï¼Œå¦‚æœä¸€ä¸ªæ³¨æ„åŠ›å±‚æœ‰`H`ä¸ªæŸ¥è¯¢å¤´ï¼Œè¿™äº›æŸ¥è¯¢å¤´è¢«åˆ†æˆ`G`ç»„ï¼ˆ`G < H`ï¼‰ï¼Œæ¯ç»„å…±äº«ç›¸åŒçš„Kå’ŒVå‘é‡ã€‚
>
> åœ¨GQAæœºåˆ¶ä¸‹ï¼Œé”®å’Œå€¼å‘é‡çš„è®¡ç®—æ¬¡æ•°å‡å°‘ï¼Œå› ä¸ºåŒä¸€ç»„å†…çš„å¤šä¸ªæŸ¥è¯¢å¤´å…±äº«ç›¸åŒçš„Kå’ŒVã€‚è¿™å‡å°‘äº†çŸ©é˜µä¹˜æ³•çš„æ¬¡æ•°ï¼Œä»è€Œé™ä½äº†è®¡ç®—å¤æ‚åº¦ã€‚



### YI-1.5
[![arXiv](https://img.shields.io/badge/arXiv-2403.04652-b31b1b.svg)](https://arxiv.org/abs/2403.04652) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/01-ai/Yi-1.5) 
[![Hugging Face collections](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-collections-blue)](https://huggingface.co/collections/01-ai/yi-15-2024-05-663f3ecab5f815a3eaca7ca8)

- **Date:** 2023-05
- **Pretrain Data Scale:** 3.6T
- **Language Support:** Multiple
- **Parameter Size:** 6B/9B/34B

Yi-1.5æ¨¡å‹é¢„è®­ç»ƒåœ¨5000äº¿é«˜è´¨é‡è¯­æ–™åº“ä¸Šï¼Œå¹¶åœ¨300ä¸‡å¤šæ ·åŒ–æ ·æœ¬ä¸Šè¿›è¡Œäº†å¾®è°ƒã€‚è¿™ç§å¤§è§„æ¨¡çš„æ•°æ®è®­ç»ƒä½¿å¾—æ¨¡å‹åœ¨ç¼–ç¨‹ã€æ•°å­¦ã€æ¨ç†å’ŒæŒ‡ä»¤éµå¾ªä»»åŠ¡ä¸Šçš„æ€§èƒ½æ›´å¼ºã€‚åŒ…æ‹¬34Bã€9Bå’Œ6Bå‚æ•°æ¨¡å‹ï¼Œæ¯ç§æ¨¡å‹æ”¯æŒçš„ä¸Šä¸‹æ–‡é•¿åº¦åˆ†åˆ«ä¸º4Kã€16Kå’Œ32Kã€‚

åœ¨Yi-1.5ç³»åˆ—ä¸­ç‰¹åˆ«æ˜¯9Bæ¨¡å‹ï¼Œé‡‡ç”¨äº†**åæœŸå±‚çš„å¤åˆ¶æ–¹æ³•**ä»¥æé«˜æ¨¡å‹æ€§èƒ½ï¼ŒåŒæ—¶ä¿æŒé«˜æ•ˆçš„è®­ç»ƒã€‚ä¸ä¼ ç»Ÿçš„æ¨¡å‹æ‰©å±•æ–¹æ³•ç›¸æ¯”ï¼Œè¿™ç§æ–¹æ³•èƒ½æ›´å¥½åœ°ä¿æŒæ€§èƒ½ï¼Œå‡å°‘æŸå¤±ã€‚

æœ€å¤§çš„ Yi 1.5. 34B åœ¨åŸºå‡†æµ‹è¯•ä¸­å‡ ä¹ä¸ Meta Llama 3 70B ç›¸å½“ã€‚

> Yi-34B-200Kåœ¨â€œNeedle-in-a-Haystackâ€æµ‹è¯•ä¸­çš„è¡¨ç°ä»89.3%æé«˜åˆ°99.8%







### Zephyr
[![arXiv](https://img.shields.io/badge/arXiv-2310.16944-b31b1b.svg)](https://arxiv.org/abs/2310.16944) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/huggingface/alignment-handbook) 
- **Date:** 2023-05
- **Pretrain Data Scale:** According to LLM
- **Language Support:** en
- **Parameter Size:** 7B

Zephyr ç³»åˆ—å¤§è¯­è¨€æ¨¡å‹é‡‡ç”¨äº†å¤šæ ·çš„åå¥½ä¼˜åŒ–æŠ€æœ¯ï¼Œä½¿å…¶æ›´ç¬¦åˆç‰¹å®šçš„ç”¨æˆ·åå¥½æˆ–ä»»åŠ¡éœ€æ±‚ã€‚è¿™ä¸ªç³»åˆ—å…±æœ‰ä¸‰ä¸ªæ¨¡å‹ï¼Œæ¯ä¸ªæ¨¡å‹ä½¿ç”¨äº†ä¸åŒçš„åå¥½ä¼˜åŒ–ç®—æ³•å’Œåº•åº§LLMã€‚

> åå¥½ä¼˜åŒ–æŠ€æœ¯å¯ä»¥ç¡®ä¿ç”Ÿæˆçš„è¾“å‡ºæ›´ç¬¦åˆæœŸæœ›ï¼Œ**å‡å°‘ä¸è‰¯è¾“å‡º**ï¼Œå¯ä»¥æå¤§åœ°å¢å¼ºæ¨¡å‹çš„å®šåˆ¶åŒ–èƒ½åŠ›ã€‚



#### Zephyr-7B

[![Hugging Face collections](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-collections-blue)](https://huggingface.co/collections/HuggingFaceH4/zephyr-7b-6538c6d6d5ddd1cbb1744a66
)

Zephyr-7B-Î² æ˜¯Zephyr ç³»åˆ—åˆ—ä¸­çš„ç¬¬ä¸€ä¸ªæ¨¡å‹ï¼Œæ˜¯åŸºäº [Mistralai/Mistral-7B-v0.1](https://link.zhihu.com/?target=https%3A//huggingface.co/mistralai/Mistral-7B-v0.1) å¾®è°ƒè€Œæ¥çš„ï¼Œä½¿ç”¨çš„æ˜¯**ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰**ç®—æ³•

æ­¤å¤–è¯¥æ¨¡å‹åˆ©ç”¨çŸ¥è¯†è’¸é¦æŠ€æœ¯ï¼Œå³ç”¨è¾ƒå°çš„â€œå­¦ç”Ÿâ€æ¨¡å‹å­¦ä¹ å’Œå¤åˆ¶è¾ƒå¤§â€œæ•™å¸ˆâ€æ¨¡å‹çš„æ€§èƒ½ã€‚è¿™ä½¿å¾—Zephyr-7Båœ¨ä¿ç•™è¾ƒå¤§æ¨¡å‹èƒ½åŠ›çš„åŒæ—¶ï¼Œå…·æœ‰æ›´é«˜çš„è®¡ç®—æ•ˆç‡ï¼Œå¹¶ä¸”æ›´å®¹æ˜“éƒ¨ç½²åœ¨è®¡ç®—èµ„æºæœ‰é™çš„è®¾å¤‡ä¸Šã€‚

ä½¿ç”¨çš„æ•°æ®é›†æ˜¯UltraChatå’ŒUltraFeedbackæ•°æ®é›†

- UltraChatæ˜¯ç”±ChatGPTç”Ÿæˆçš„åˆæˆå¯¹è¯æ•°æ®é›†
- UltraFeedbackåŒ…å«äº†å„ç§æç¤ºå’Œå“åº”ï¼Œå¹¶ç”±GPT-4è¿›è¡Œäº†æ³¨é‡Š

>ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDirect Preference Optimization, DPOï¼‰é€šè¿‡ç›´æ¥æœ€å¤§åŒ–æ¨¡å‹ç”Ÿæˆçš„é¦–é€‰å“åº”çš„æ¦‚ç‡æ¥è¿›è¡Œåå¥½å¯¹é½ã€‚DPOç®—æ³•é€šè¿‡ç›´æ¥ä¼˜åŒ–æ¨¡å‹ç”Ÿæˆçš„é¦–é€‰å“åº”çš„æ¦‚ç‡ï¼Œè€Œä¸éœ€è¦å‚è€ƒæ¨¡å‹ï¼Œç®€åŒ–äº†è®­ç»ƒè¿‡ç¨‹ã€‚



#### Zephyr ORPO
[![Hugging Face collections](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-collections-blue)](https://huggingface.co/collections/HuggingFaceH4/zephyr-orpo-6617eba2c5c0e2cc3c151524)

Zephyr-ORPO-141B-A35b-v0.1æ˜¯ä¸€ä¸ªå…·æœ‰ 141B æ€»å‚æ•°å’Œ 39B æœ‰æ•ˆå‚æ•°çš„ä¸“å®¶æ··åˆ ï¼ˆMoEï¼‰ æ¨¡å‹ï¼Œæ˜¯åœ¨[Mixtral-8x22B-v0.1](https://huggingface.co/mistral-community/Mixtral-8x22B-v0.1)çš„åŸºç¡€ä¸Šå¾®è°ƒçš„ã€‚é‡‡ç”¨[Odds Ratio Preference Optimization (ORPO)](https://huggingface.co/papers/2403.07691)ç®—æ³•è¿›è¡Œåå¥½ä¼˜åŒ–ï¼ŒORPO ä¸éœ€è¦ SFT æ­¥éª¤å³å¯å®ç°é«˜æ€§èƒ½ï¼Œå› æ­¤è®¡ç®—æ•ˆç‡æ¯” DPO å’Œ PPO ç­‰æ–¹æ³•é«˜å¾—å¤šã€‚

ORPOæ¨¡å‹é€šè¿‡åŠ¨æ€æƒ©ç½šæœºåˆ¶è¿˜å¯ä»¥æœ‰æ•ˆåœ°å‡å°‘äº†ä¸è‰¯å“åº”çš„ç”Ÿæˆï¼Œç¡®ä¿è¾“å‡ºå†…å®¹çš„é«˜è´¨é‡å’Œé€‚ç”¨æ€§ã€‚

> **Odds Ratio Preference Optimization (ORPO)** ç®—æ³•é€šè¿‡è®¡ç®—é¦–é€‰å“åº”å’Œéé¦–é€‰å“åº”çš„èµ”ç‡æ¯”è¿›è¡Œä¼˜åŒ–ï¼Œç¡®ä¿æ¨¡å‹æ›´å€¾å‘äºç”Ÿæˆé¦–é€‰å“åº”ã€‚



#### Zephyr-7B Gemma
[![Hugging Face collections](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-collections-blue)](https://huggingface.co/collections/HuggingFaceH4/zephyr-7b-gemma-65e1fd82d26b426e3e63d956)

æ˜¯åœ¨HuggingFaceH4/deita-10k-v0-sft æ•°æ®é›†ä¸Š [google/gemma-7b](https://huggingface.co/google/gemma-7b) çš„å¾®è°ƒç‰ˆæœ¬ï¼Œä½¿ç”¨çš„ä¹Ÿæ˜¯DPOçš„åå¥½ä¼˜åŒ–ç®—æ³•ã€‚



### StripedHyena
[![AI Blog](https://img.shields.io/badge/AI%20Blog-Phi%20AI-orange.svg)](https://www.together.ai/blog/stripedhyena-7b) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/togethercomputer/stripedhyena) 

[![Hugging Face collections](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-collections-blue)](https://huggingface.co/collections/togethercomputer/stripedhyena-65d8e6e77540dd1da932dbe1)

-  2023-12
- **Pretrain Data Scale:** 2T
- **Language Support:** Multiple
- **Parameter Size:** 7B

è¯¥æ¨¡å‹ç³»åˆ—åŒ…æ‹¬ StripedHyena-Hessian-7B å’Œ StripedHyena-Nous-7B ä¸¤ä¸ªä¸»è¦å˜ç§ã€‚[å‰è€…](https://huggingface.co/togethercomputer/StripedHyena-Hessian-7B)ä¸ºåŸºç¡€æ¨¡å‹[åè€…](https://huggingface.co/togethercomputer/StripedHyena-Nous-7B)ä¸ºèŠå¤©æ¨¡å‹

StripedHyena é‡‡ç”¨äº†ä¸€ç§æ··åˆæ¶æ„ï¼Œç»“åˆäº†é—¨æ§å·ç§¯ï¼ˆgated convolutionsï¼‰å’Œåˆ†ç»„æŸ¥è¯¢æ³¨æ„åŠ›æœºåˆ¶ï¼ˆgrouped-query attentionï¼‰ã€‚è¯¥æ¨¡å‹çš„æ ¸å¿ƒç»„ä»¶æ˜¯çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMï¼‰å±‚ï¼Œä¼ ç»Ÿä¸Šç”¨äºå»ºæ¨¡å¤æ‚åºåˆ—å’Œæ—¶é—´åºåˆ—æ•°æ®ã€‚SSM å±‚èƒ½å¤Ÿæ›´é«˜æ•ˆåœ°å¤„ç†é•¿åºåˆ—ä»»åŠ¡ï¼Œå‡å°‘è®¡ç®—èµ„æºéœ€æ±‚ï¼Œç›¸è¾ƒäºç»å…¸çš„ Transformerï¼Œåœ¨é•¿åºåˆ—è®­ç»ƒä¸­é€Ÿåº¦æ›´å¿«ã€‚

StripedHyena è®­ç»ƒåºåˆ—é•¿åº¦å¯è¾¾ 32kï¼Œèƒ½å¤Ÿå¤„ç†æ›´é•¿çš„æç¤º



### Persimmon
[![AI Blog](https://img.shields.io/badge/AI%20Blog-Phi%20AI-orange.svg)](https://www.adept.ai/blog/persimmon-8b) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/persimmon-ai-labs/adept-inference) 
[![Hugging Face model](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-models-blue)](https://huggingface.co/adept/persimmon-8b-chat)

- **Date:** 2023-09
- **Pretrain Data Scale:**  0.737T
- **Language Support:** en
- **Parameter Size:** 8B

Persimmon-8B æ”¯æŒ 16K çš„ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œæ˜¯ LLaMA2 çš„å››å€ï¼ŒGPT-3 çš„å…«å€

é‡‡ç”¨äº†ä¸€äº›æ¶æ„ä¼˜åŒ–ï¼ŒåŒ…æ‹¬å¹³æ–¹ ReLU æ¿€æ´»å‡½æ•°å’Œæ—‹è½¬ä½ç½®ç¼–ç ï¼ˆrotary positional encodingsï¼‰ã€‚

æ¨¡å‹çš„è¾“å…¥å’Œè¾“å‡ºåµŒå…¥è¿›è¡Œäº†åˆ†ç¦»ä¼˜åŒ–ï¼Œé¿å…äº†å¤§åµŒå…¥å±‚æ¢¯åº¦çš„å…¨é‡å‡å°‘ï¼Œä»è€Œæå‡äº†è®­ç»ƒæ•ˆç‡ã€‚







## æ¨¡å‹è¯„ä¼°å¹³å°

### OpenLLM Leaderboard by Hugging Face[[Leaderboard]](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)

Hugging Faceçš„OpenLLMæ’è¡Œæ¦œæ˜¯ä¸€ä¸ªæ—¨åœ¨è¿½è¸ªã€è¯„çº§å’Œè¯„ä¼°å¼€æºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’ŒèŠå¤©æœºå™¨äººçš„å¹³å°ã€‚è¿™ä¸ªæ’è¡Œæ¦œæä¾›äº†ä¸€ä¸ªé›†ä¸­çš„å¹³å°ã€‚

[Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard) is actually just a wrapper running the open-source benchmarking library [Eleuther AI LM Evaluation Harness](https://github.com/EleutherAI/lm-evaluation-harness) created by the [EleutherAI non-profit AI research lab](https://www.eleuther.ai/) famous for creating [The Pile](https://pile.eleuther.ai/) and training [GPT-J](https://huggingface.co/EleutherAI/gpt-j-6b), [GPT-Neo-X 20B](https://huggingface.co/EleutherAI/gpt-neox-20b), and [Pythia](https://github.com/EleutherAI/pythia). A team with serious credentials in the AI space!ï¼ˆCitation from Hugging Face blogï¼‰



### Chatbot Arena by LMSYS and SkyLab[[Chatbot Arena]](https://arena.lmsys.org/)

Chatbot Arenaçš„ä¸»è¦åŠŸèƒ½ä»‹ç»ï¼š

1. **æ¨¡å‹å¯¹æˆ˜ï¼ˆArena Battleï¼‰**ï¼šåœ¨Chatbot Arenaä¸­ï¼Œç”¨æˆ·å¯ä»¥é€‰æ‹©ä¸¤ä¸ªä¸åŒçš„åŒ¿åæ¨¡å‹ï¼ˆå¦‚ChatGPTã€Claudeã€Llamaç­‰ï¼‰ï¼Œå¹¶å°†å®ƒä»¬è¿›è¡Œå¯¹æ¯”ã€‚åœ¨ä¸€ä¸ªå®‰å…¨çš„æ¯”èµ›ç¯å¢ƒä¸­ï¼Œç”¨æˆ·å¯ä»¥æé—®å¹¶è¯„ä¼°ä¸¤ä¸ªæ¨¡å‹çš„å›ç­”ï¼Œé€šè¿‡æŠ•ç¥¨å†³å®šå“ªä¸ªæ¨¡å‹è¡¨ç°æ›´å‡ºè‰²ã€‚è¿™ä¸€æ¯”è¾ƒè¿‡ç¨‹å¯ä»¥å¤šè½®è¿›è¡Œï¼Œç›´åˆ°ç¡®å®šæœ€ç»ˆçš„èƒœåˆ©è€…ã€‚ä¸ºäº†ä¿è¯æ¯”èµ›çš„å…¬å¹³æ€§ï¼Œå¦‚æœæŸè½®å¯¹è¯æš´éœ²äº†æ¨¡å‹çš„å…·ä½“èº«ä»½ï¼Œè¯¥è½®çš„æŠ•ç¥¨ç»“æœå°†è¢«æ’é™¤ã€‚
2. **å®æ—¶èŠå¤©ï¼ˆDirect Chatï¼‰**ï¼šChatbot Arenaæä¾›äº†ä¸€ä¸ªå®æ—¶èŠå¤©åŠŸèƒ½ï¼Œå…è®¸ç”¨æˆ·ç›´æ¥ä¸é€‰å®šçš„æ¨¡å‹è¿›è¡Œå¯¹è¯ã€‚æ— è®ºç”¨æˆ·é€‰æ‹©çš„æ˜¯æ–‡æœ¬è¿˜æ˜¯è§†è§‰èŠå¤©æ¨¡å¼ï¼Œéƒ½èƒ½å³æ—¶æ¥æ”¶åˆ°æ¨¡å‹çš„åé¦ˆã€‚
3. **æ’è¡Œæ¦œï¼ˆLeaderboardï¼‰**ï¼šChatbot Arenaé€šè¿‡åˆ†æè¶…è¿‡300,000ä¸ªäººç±»ç”¨æˆ·çš„æŠ•ç¥¨ç»“æœï¼Œé‡‡ç”¨åŸºäºEloç³»ç»Ÿçš„æ–¹æ³•æ¥è¯„ä¼°å„ä¸ªLLMçš„æ’åã€‚è¿™è®©ç”¨æˆ·èƒ½å¤Ÿç›´è§‚åœ°äº†è§£å“ªäº›æ¨¡å‹å½“å‰å¤„äºé¢†å…ˆåœ°ä½ï¼Œè½»æ¾è¯†åˆ«å‡ºLLMé¢†åŸŸçš„ä½¼ä½¼è€…ã€‚



## Benchmarks

### ARC (AI2 Reasoning Challenge)

[![Paper with Code](https://img.shields.io/badge/Paper%20with%20Code-arc%20challenge-blue.svg)](https://paperswithcode.com/sota/common-sense-reasoning-on-arc-challenge)
[![Paper with Code](https://img.shields.io/badge/Paper%20with%20Code-arc%20easy-blue.svg)](https://paperswithcode.com/sota/common-sense-reasoning-on-arc-easy)
[![arXiv](https://img.shields.io/badge/arXiv-2305.18354-b31b1b.svg)](https://arxiv.org/pdf/2305.18354) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/fchollet/ARC) 

The ARC (Abstraction and Reasoning Corpus) benchmark is a challenging framework used to evaluate the performance of large language models, particularly in their ability to perform tasks that require both abstraction and reasoning. This benchmark is part of an effort to push the boundaries of what AI models can achieve beyond standard pattern recognition tasks that are common in many benchmarks today.

##### Key Features of ARC

- **Task Design**: The tasks in ARC are designed to be straightforward for humans but challenging for AI. Each task involves an input and a correct output, with the goal being to predict the output from the input by discerning the underlying pattern or rule. The tasks cover various types of cognitive functions, including pattern recognition, spatial reasoning, and logical deduction.
- **Dataset**: The ARC dataset is publicly available and consists of a training set and a test set, where the test set contains completely novel tasks that require generalizing beyond the training data. This setup is intended to simulate real-world learning scenarios where direct answers are not always available, and reasoning must be applied.
- **Evaluation**: Success in ARC requires developing models that can truly understand and manipulate abstract concepts, making it a stringent test of an AIâ€™s reasoning abilities rather than just its data processing capabilities.



### HellaSwag

[![Paper with Code](https://img.shields.io/badge/Paper%20with%20Code-hellaswag-blue.svg)](https://paperswithcode.com/sota/sentence-completion-on-hellaswag)
[![arXiv](https://img.shields.io/badge/arXiv-1905.07830-b31b1b.svg)](https://arxiv.org/abs/1905.07830) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/rowanz/hellaswag) 

**HellaSwag** is a benchmark designed to evaluate the performance of language models on commonsense natural language inference. It specifically tests the model's ability to predict the continuation of straightforward descriptions of everyday activities, which are obvious to humans but potentially challenging for algorithms. The benchmark consists of numerous multiple-choice questions, each providing a scenario and four possible continuations, from which the model must select the most appropriate one.

The questions in HellaSwag primarily derive from two domains: ActivityNet and WikiHow, enriching the dataset with practical relevance and diversity. The correct answer describes the actual next event, while the other three incorrect options are adversarially generated and human-verified to mislead models but not humans.

The construction of HellaSwag includes an "Adversarial Filtering" technique, where a series of discriminators iteratively select machine-generated wrong answers that effectively deceive models. This method has proven its effectiveness in challenging models to recognize real-world scenarios and has highlighted the limitations of even state-of-the-art models.



### MMLU (Massive Multitask Language Understanding)

[![Paper with Code](https://img.shields.io/badge/Paper%20with%20Code-MMLU-blue.svg)](https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu?tag_filter=183)
[![arXiv](https://img.shields.io/badge/arXiv-2009.03300-b31b1b.svg)](https://arxiv.org/abs/2009.03300) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/hendrycks/test) 

This is a broad and diverse benchmark that evaluates a model's understanding across a wide range of subjects, from humanities to science. It's designed to test the model's general knowledge and understanding capabilities on various topics.

> æ³¨æ„ï¼šMMLUçš„è¯„ä¼°åŒ…å«ä¸‰ç§å½¢å¼ï¼Œåˆ†åˆ«æ˜¯MMLU (HELM)ã€MMLU (Harness)å’ŒMMLU (Original)ã€‚æ›¾ç»ï¼Œåœ¨Hugging Faceçš„OpenLLMæ’è¡Œæ¦œä¸Šï¼Œ[**LLaMA model ğŸ¦™**](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/)è¢«çˆ†å‡ºMMLUè¯„ä¼°ç»“æœæ˜æ˜¾ä½äº[å·²å‘è¡¨çš„ LLaMa è®ºæ–‡](https://arxiv.org/abs/2302.13971)ä¸­çš„æ•°å­—ã€‚æœ€ç»ˆ[Blog](https://huggingface.co/blog/open-llm-leaderboard-mmlu)ä¸Šçš„å£°æ˜å°†è¿™ä¸ªç°è±¡å½’ç»“ä¸ºç”¨äºæµ‹è¯•çš„MMLU benchmarkçš„ç»†èŠ‚ä¸åŒå¯¼è‡´äº†ç»“æœä¸åŒï¼Œè¯¦æƒ…å¯å‚è§[Blog](https://huggingface.co/blog/open-llm-leaderboard-mmlu)



### TruthfulQA

[![Paper with Code](https://img.shields.io/badge/Paper%20with%20Code-truthfulqa-blue.svg)](https://paperswithcode.com/sota/question-answering-on-truthfulqa)
[![arXiv](https://img.shields.io/badge/arXiv-2109.07958-b31b1b.svg)](https://arxiv.org/abs/2109.07958) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/sylinrl/TruthfulQA) 

This benchmark evaluates a model's ability to provide truthful answers. It focuses on minimizing the spread of misinformation by testing how models handle questions that might typically lead to untruthful or misleading answers.

**TruthfulQA** is a benchmark designed to assess the truthfulness of answers generated by large language models. It consists of 817 questions across 38 categories, including sectors like health, law, finance, and politics. The questions are designed to probe models on their ability to handle scenarios where humans might respond incorrectly due to misconceptions or false beliefs. The main goal of TruthfulQA is to measure how accurately models can generate truthful responses. The benchmark employs various tasks and modes, including single and multiple-choice questions as well as generative tasks, to evaluate a model's capacity to identify and generate truthful answers.

##### Tasks and Evaluation Methods

TruthfulQA includes two primary tasks:

1. **Generation Task**: Models are given a question and must generate a one to two-sentence answer. The primary metric for this task is the overall truthfulness of the modelâ€™s answers, assessed against a standard where the truth must describe the literal truth about the real world. Secondary metrics include informativeness, assessed by whether the model provides meaningful information rather than evasive responses.
2. **Multiple-Choice Task**: This task comes in two forms:
   - **MC1 (Single-true)**: Models are provided with a question and several answer choices, and they must select the single correct answer.
   - **MC2 (Multi-true)**: Models are given multiple true and false reference answers and must identify all correct answers.

##### Important Points

- **Adversarial Nature**: The questions in TruthfulQA are adversarially designed to test models on potential weaknesses in generating truthful answers. This includes crafting questions that leverage common misconceptions or that models might commonly answer falsely due to their training on biased data distributions.
- **Validation and Benchmarks**: The benchmark includes validation mechanisms where external researchers assess the truthfulness and accuracy of the reference answers, ensuring the robustness of the benchmark's evaluations.



### Winogrande

[![Paper with Code](https://img.shields.io/badge/Paper%20with%20Code-Winogrande-blue.svg)](https://paperswithcode.com/sota/common-sense-reasoning-on-winogrande)
[![arXiv](https://img.shields.io/badge/arXiv-1907.10641-b31b1b.svg)](https://arxiv.org/pdf/1907.10641) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/allenai/winogrande) 

WINOGRANDE is a language understanding benchmark based on the Winograd Schema Challenge (WSC) designed to evaluate the performance of large language models (LLMs) in solving pronoun resolution problems that require common sense and reasoning abilities. By offering a larger and more challenging dataset than the original WSC, WINOGRANDE is better suited for assessing the capabilities of modern artificial intelligence language models.

Developed by the Allen Institute for AI, the purpose of the WINOGRANDE benchmark is to test models' reasoning abilities through pronoun resolution tasks. These tasks typically involve a sentence with a pronoun and multiple potential referents, and the model needs to determine the correct referent for the pronoun. For example:

```less
Sentence: The elephant put the apple there because it was ______.
Options: A) empty B) heavy
Correct Answer: A) empty
```

This type of question requires the model to understand not just the literal meaning of the language but also to reason about implicit relationships within the context.



### GSM8K (Grade School Math 8K)

[![Paper with Code](https://img.shields.io/badge/Paper%20with%20Code-GSM8K-blue.svg)](https://paperswithcode.com/dataset/gsm8k)
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/openai/grade-school-math) 

The GSM8K (Grade School Math 8K) dataset, developed by OpenAI, is designed to evaluate the performance of large language models on solving elementary school-level math problems. The benchmark consists of 8,500 high-quality, linguistically diverse math word problems that require basic arithmetic operations such as addition, subtraction, multiplication, and division. These problems typically take between two to eight steps to solve. The dataset is divided into 7,500 training problems and 1,000 test problems, aimed at testing the models' capabilities in multi-step mathematical reasoning. GSM8K is particularly useful for assessing how well models handle problems that involve sequential logic and computational steps.

