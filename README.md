<div align="center">
  <img src="./image/title.png" width="800" />
</div>
<div align="center">
<strong>üåê‚ú®Summarizing the latest LLMs and VLMs! Helping you quickly and easily choose and use large models! üòÑ</strong><br>
<strong>This is the repository navigation page, the main Awesome List: <a href="./README_LLM.md">LLMsüöÄ</a></strong> | <strong><a href="./README_LVLMs.md">LVLMsüöÄ</a></strong><br>
<strong>Supported languages: <a href="./README_zh.md">‰∏≠ÊñáüöÄ</a></strong> | <strong>English</strong>
</div>
<br>

Welcome to our repositoryü•∞, a comprehensive navigation page that connects you to the most relevant resources and summary platforms for the latest large models (including <a href="./README_LLM.md">LLMsüöÄ</a> and <a href="./README_LVLMs.md">LVLMsüöÄ</a>). Whether you're looking for benchmarksüíØ, comparisons‚öñÔ∏è, or surveysüìñ, we've got you covered. 

Feel free to raise a issue or contact us if you find any related papers that are not included here. Organizer: Bocheng Hu@NKU (h1355393774@gmail.com), Gepeng Ji@ANU (gepengai.ji@gmail.com)

## Quick Start ‚Äî‚Äî large language models (LLMs) üèÅ

|    Model     |    Date    |     Organization      |        Paper        |                          Parameters                          |                           CheckPoint                  | Details |
| :----------: | :-------------------: | :----------------------------------------------------------: | :----------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
|    Gemma2    | 2024-06  |        Google         | [![AI Blog](https://img.shields.io/badge/AI%20Blog-Gemma2%20AI-orange.svg)](https://storage.googleapis.com/deepmind-media/gemma/gemma-2-report.pdf) |       2.6B/9B/27B        | [Gemma2 Familyü§ó](https://huggingface.co/collections/google/gemma-2-release-667d6600fd5220e7b967f315) | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM.md#gemma2)/[CH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM_zh.md#gemma2) |
|    YI-1.5    |    2024-05    |         01-ai         | [![arXiv](https://img.shields.io/badge/arXiv-2403.04652-b31b1b.svg)](https://arxiv.org/abs/2403.04652) |        6B/9B/34B         | [Yi-1.5 Familyü§ó](https://huggingface.co/collections/01-ai/yi-15-2024-05-663f3ecab5f815a3eaca7ca8) | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM.md#yi-15)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM_zh.md#yi-15) |
|   Llama 3    | 2024-04 |         Meta          | [![AI Blog](https://img.shields.io/badge/AI%20Blog-Meta%20AI-orange.svg)](https://ai.meta.com/blog/) |          8B/70B          | [Llama3 Familyü§ó](https://huggingface.co/collections/meta-llama/meta-llama-3-66214712577ca38149ebb2b6) | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM.md#llama3)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM_zh.md#llama3) |
|     phi3     |     2024-04     |       Microsoft       | [![arXiv](https://img.shields.io/badge/arXiv-2404.14219-b31b1b.svg)](https://arxiv.org/abs/2404.14219) |       3.8B/7B/14B        | [Phi-3 familyü§ó **(only phi-3-mini is available now)**](https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3) | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM.md#phi3)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM_zh.md#phi3) |
|    Gemma     | 2024-02 |        Google         | [![AI Blog](https://img.shields.io/badge/AI%20Blog-Phi%20AI-orange.svg)](https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf) |          2B/7B           | [Gemma Familyü§ó](https://huggingface.co/collections/google/gemma-release-65d5efbccdbb8c4202ec078b) | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM.md#gemma)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM_zh.md#gemma) |
|   Qwen1.5    | 2024-02 |        Alibaba        | [![AI Blog](https://img.shields.io/badge/AI%20Blog-QWen%20AI-orange.svg)](https://qwen.readthedocs.io/en/latest/) | 0.5B/1.8B/4B/7B/14B/72B  |           [Qwen1.5ü§ó](https://huggingface.co/Qwen)            | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM.md#qwen15)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM_zh.md#qwen15) |
|     phi      |   2023-12 |       Microsoft       | [![AI Blog](https://img.shields.io/badge/AI%20Blog-Phi%20AI-orange.svg)](https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/) |        1B/1.5B/2B        | [phi-1Bü§ó](https://huggingface.co/microsoft/phi-1)<br />[phi-1.5Bü§ó](https://huggingface.co/microsoft/phi-1_5)<br />[phi-2Bü§ó](https://huggingface.co/microsoft/phi-2) | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM.md#phi)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM_zh.md#phi) |
|    Mamba     | 2023-12 | Albert Gu and Tri Dao | [![arXiv](https://img.shields.io/badge/arXiv-2312.00752-b31b1b.svg)](https://arxiv.org/abs/2312.00752) | 130M/370M/790M/1.4B/2.8B |     [state-spacesü§ó](https://huggingface.co/state-spaces)     | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM.md#mamba)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM_zh.md#mamba) |
| StripedHyena | 2023-12 |      Together AI      | [![AI Blog](https://img.shields.io/badge/AI%20Blog-Phi%20AI-orange.svg)](https://www.together.ai/blog/stripedhyena-7b) |            7B            | [StripedHyena Familyü§ó](https://huggingface.co/collections/togethercomputer/stripedhyena-65d8e6e77540dd1da932dbe1) | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM.md#stripedhyena)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM_zh.md#stripedhyena) |
|      YI      |      2023-11      |         01-ai         | [![arXiv](https://img.shields.io/badge/arXiv-2403.04652-b31b1b.svg)](https://arxiv.org/abs/2403.04652) |        6B/9B/34B         | [Yi Family](https://huggingface.co/collections/01-ai/yi-2023-11-663f3f19119ff712e176720f) | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM.md#yi)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM_zh.md#yi) |
|    Orca2     | 2023-11 |       Microsoft       | [![arXiv](https://img.shields.io/badge/arXiv-2311.11045-b31b1b.svg)](https://arxiv.org/pdf/2311.11045.pdf) |          7B/13B          | [Orca Familyü§ó](https://huggingface.co/collections/microsoft/orca-65bbeef1980f5719cccc89a3) | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM.md#orca2)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM_zh.md#orca2) |
|   Mistral    | 2023-09 |      Mistral AI       | [![arXiv](https://img.shields.io/badge/arXiv-2310.06825-b31b1b.svg)](https://arxiv.org/abs/2310.06825) |            7B            |         [Mistralü§ó](https://huggingface.co/mistralai)         | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM.md#mistral)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM_zh.md#mistral) |
|  Persimmon   | 2023-09 |     Adept AI Labs     | [![AI Blog](https://img.shields.io/badge/AI%20Blog-Phi%20AI-orange.svg)](https://www.adept.ai/blog/persimmon-8b) |            8B            | [persimmon-8b-chatü§ó](https://huggingface.co/adept/persimmon-8b-chat) | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM.md#persimmon)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM_zh.md#persimmon) |
|     Qwen     |     2023-08     |        Alibaba        | [![arXiv](https://img.shields.io/badge/arXiv-2309.16609-b31b1b.svg)](https://arxiv.org/abs/2309.16609) | 0.5B/1.8B/4B/7B/14B/72B  |             [Qwenü§ó](https://huggingface.co/Qwen)             | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM.md#qwen)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM_zh.md#qwen) |
|   Llama 2    | 2023-07 |         Meta          | [![arXiv](https://img.shields.io/badge/arXiv-2307.09288-b31b1b.svg)](https://arxiv.org/abs/2307.09288) |        7B/13B/70B        | [Llama2 Familyü§ó](https://huggingface.co/collections/meta-llama/llama-2-family-661da1f90a9d678b6f55773b) | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM.md#llama2)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM_zh.md#llama2) |
|    Falcon    |    2023-07    |          UAE          | [![AI Blog](https://img.shields.io/badge/AI%20Blog-Falcon%20AI-orange.svg)](https://huggingface.co/blog/falcon-180b) |    1.3B/7.5B/40B/180B    | [Falcon Familyü§ó](https://huggingface.co/collections/tiiuae/falcon-64fb432660017eeec9837b5a) | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM.md#falcon)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM_zh.md#falcon) |
|     XGen     |     2023-07     |      Salesforce       | [![arXiv](https://img.shields.io/badge/arXiv-2309.03450-b31b1b.svg)](https://arxiv.org/abs/2309.03450) |            7B            | [xgen-7b-4k-baseü§ó](https://huggingface.co/Salesforce/xgen-7b-4k-base) | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM.md#xgen)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM_zh.md#xgen) |
|    Zephyr    |    2023-05    |     Hugging Face      | [![arXiv](https://img.shields.io/badge/arXiv-2310.16944-b31b1b.svg)](https://arxiv.org/abs/2310.16944) |            7B            |   [HuggingFaceH4ü§ó ](https://huggingface.co/HuggingFaceH4)    | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM.md#zephyr)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM_zh.md#zephyr) |
|    Pythia    |    2023-04    |      EleutherAI       | [![arXiv](https://img.shields.io/badge/arXiv-2304.01373-b31b1b.svg)](https://arxiv.org/abs/2304.01373) |         14MÔΩû12B         | [Pythia Familyü§ó](https://huggingface.co/collections/EleutherAI/pythia-scaling-suite-64fb5dfa8c21ebb3db7ad2e1) | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM.md#pythia)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM_zh.md#pythia) |
|    Vicuna    |    2023-03    |         LMSYS         | [![AI Blog](https://img.shields.io/badge/AI%20Blog-Vicuna%20AI-orange.svg)](https://lmsys.org/blog/2023-03-30-vicuna/) |        7B/13B/33B        |           [Vicunaü§ó](https://huggingface.co/lmsys)            | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM.md#vicuna)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LLM_zh.md#vicuna) |



## Quick Start ‚Äî‚Äî (large vision language models) LVLMsüèÅ

|           Model           |  Date   | Publication  |    Parameters     |                             Demo                             |                            Paper                             | Github                                                       |                          CheckPoint                          | Details                                                      |
| :-----------------------: | :-----: | :----------: | :---------------: | :----------------------------------------------------------: | :----------------------------------------------------------: | ------------------------------------------------------------ | :----------------------------------------------------------: | ------------------------------------------------------------ |
| üî•newüî•<br />Cambrian-1 | 2024-06 | arXiv | 3B/8B/13B/34B | --- | [![arXiv](https://img.shields.io/badge/Arxiv-2406.16860-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2406.16860) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/cambrian-mllm/cambrian) | [Cambrian-1](https://huggingface.co/collections/nyu-visionx/cambrian-1-models-666fa7116d5420e514b0f23c)ü§ó | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs.md#cambrian1)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs_zh.md#cambrian1) |
|   üî•newüî•<br />EVE    | 2024-06 |    arXiv     |        7B         |                             ---                              | [![arXiv](https://img.shields.io/badge/Arxiv-2406.11832-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2406.11832) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/baaivision/EVE) |                         comming soon                         | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs.md#eve)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs_zh.md#eve) |
|   üî•newüî•<br />Chameleon    | 2024-05 |    arXiv     |      7B/34B       |                             ---                              | [![arXiv](https://img.shields.io/badge/Arxiv-2405.09818-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2405.09818) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/facebookresearch/chameleon) |         [facebook](https://huggingface.co/facebook)          | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs.md#chameleon)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs_zh.md#chameleon) |
| üî•newüî•<br />DenseConnector | 2024-05 |    arXiv     |     2.7B‚Üí70B      |                             ---                              | [![arXiv](https://img.shields.io/badge/Arxiv-2405.13800-b31b1b.svg?logo=arXiv)](https://arxiv.org/pdf/2405.13800) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/HJYao00/DenseConnector) | [DenseConnector](https://huggingface.co/collections/HuanjinYao/denseconnector-66500e173fc8c9f05dc98dea)ü§ó | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs.md#denseconnector)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs_zh.md#denseconnector) |
|           Llava           | 2023-04 | NeurIPS 2023 |      7B/13B       | [Llava v1.6](https://huggingface.co/spaces/liuhaotian/LLaVA-1.6) | [![arXiv](https://img.shields.io/badge/arXiv-2304.08485-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2304.08485) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/haotian-liu/LLaVA) | [Llava v1.5ü§ó](https://huggingface.co/collections/liuhaotian/llava-16-65b9e40155f60fd046a5ccf2)<br />[Lava v1.6](https://huggingface.co/collections/liuhaotian/llava-15-653aac15d994e992e2677a7e)ü§ó | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs.md#llava)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs_zh.md#llava) |
|        DeepSeek-VL        | 2024-03 |    arXiv     |      1.3B/7B      | [Chat with DeepSeek VL 7B ](https://huggingface.co/spaces/deepseek-ai/DeepSeek-VL-7B) | [![arXiv](https://img.shields.io/badge/arXiv-2403.05525-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2403.05525) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/deepseek-ai/DeepSeek-VL) | [DeepSeek-VL Familyü§ó](https://huggingface.co/collections/deepseek-ai/deepseek-vl-65f295948133d9cf92b706d3) | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs.md#deepseek-vl)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs_zh.md#deepseek-vl) |
|         PaliGemma         | 2024-03 |     ---      |        3B         | [PaliGemma](https://huggingface.co/spaces/big-vision/paligemma) | [![AI Blog](https://img.shields.io/badge/AI%20Blog-PaliGemma%20AI-orange.svg)](https://ai.google.dev/gemma/docs/paligemma) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/google-research/big_vision) | [PaliGemma Familyü§ó](https://huggingface.co/collections/google/paligemma-ft-models-6643b03efb769dad650d2dda) | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs.md#paligemma)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs_zh.md#paligemma) |
|   MiniGemini<br />(MGM)   | 2024-03 |    arXiv     |   2B/7B/13B/34B   | [MGM](https://huggingface.co/spaces/jiaqianjing/Mini-Gemini) | [![arXiv](https://img.shields.io/badge/arXiv-2403.18814-b31b1b.svg?logo=arXiv)](https://arxiv.org/pdf/2403.18814) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/dvlab-research/MGM) | [MGM  Family](https://huggingface.co/collections/YanweiLi/mgm-6603c50b9b43d044171d0854)ü§ó | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs.md#minigemini)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs_zh.md#minigemini) |
|            HPT            | 2024-03 |     ---      |      3-8B/6B      |                             None                             | [![AI Blog](https://img.shields.io/badge/AI%20Blog-hypergai%20AI-orange.svg)](https://hypergai.com/blog/) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/HyperGAI/HPT/) |           [HPT](https://huggingface.co/HyperGAI)ü§ó            | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs.md#hpt)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs_zh.md#hpt) |
|           Bunny           | 2024-02 |    arXiv     |    2B/3B/4B/8B    |             [Bunny](http://bunny.dataoptim.org/)             | [![arXiv](https://img.shields.io/badge/arXiv-2402.11530-b31b1b.svg?logo=arXiv)](https://arxiv.org/pdf/2402.11530) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/BAAI-DCAI/Bunny) |             [BAAI](https://huggingface.co/BAAI)ü§ó             | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs.md#bunny)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs_zh.md#bunny) |
|         TinyLLaVA         | 2024-02 |    arXiv     |  1.4B/2.4B/3.1B   |                             None                             | [![arXiv](https://img.shields.io/badge/arXiv-2402.14289-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2402.14289) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/DLCV-BUAA/TinyLLaVABench) |        [TinyLLaVA](https://huggingface.co/tinyllava)ü§ó        | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs.md#tinyllava)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs_zh.md#tinyllava) |
|     MiniCPM-V Series      | 2024-02 |     ---      |       2B/8B       | [MiniCPM-Llama3-V-2 5 ](https://huggingface.co/spaces/openbmb/MiniCPM-Llama3-V-2_5)<br />[MiniCPM V 2 ](https://huggingface.co/spaces/openbmb/MiniCPM-V-2) | [![AI Blog](https://img.shields.io/badge/AI%20Blog-paligemma%20AI-orange.svg)](https://openbmb.vercel.app/minicpm-v-2) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/OpenBMB/MiniCPM-V) | [MiniCPM-2B Familyü§ó](https://huggingface.co/collections/openbmb/minicpm-2b-65d48bf958302b9fd25b698f) | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs.md#minicpm-v-20)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs_zh.md#minicpm-v-20) |
|       ALLaVA-Longer       | 2024-02 |    arXiv     |        3B         |       [ALLaVA-Longer](https://allava.freedomai.cn/#/)        | [![arXiv](https://img.shields.io/badge/arXiv-2402.11684-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2402.11684) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/FreedomIntelligence/ALLaVA) | [ALLaVA-3B-Longer ü§ó](https://huggingface.co/FreedomIntelligence/ALLaVA-3B-Longer) | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs.md#allava-longer)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs_zh.md#allava-longer) |
|            MM1            | 2024-02 |              |        ---        |                             None                             | [![arXiv](https://img.shields.io/badge/arXiv-2402.11684-b31b1b.svg?logo=arXiv)](https://arxiv.org/pdf/2403.09611) |                                                              |                             None                             | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs.md#mm1)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs_zh.md#mm1) |
|         Vary-toy          | 2024-01 |    arXiv     |        ---        |           [Vary Family ](https://vary.xiaomy.net/)           | [![arXiv](https://img.shields.io/badge/arXiv-2401.12503-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2401.12503) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/Ucas-HaoranWei/Vary-toy) |    [Vary-toyü§ó](https://huggingface.co/HaoranWei/Vary-toy)    | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs.md#vary-toy)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs_zh.md#vary-toy) |
|         MoE-LLaVA         | 2024-01 |    arXiv     |        3B         | [MoE LLaVA](https://huggingface.co/spaces/LanguageBind/MoE-LLaVA) | [![arXiv](https://img.shields.io/badge/arXiv-2401.15947-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2401.15947) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/PKU-YuanGroup/MoE-LLaVA) | [MoE-LLaVA Familyü§ó](https://huggingface.co/collections/LanguageBind/moe-llava-model-65b607bf2524ac36e733874c) | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs.md#moe-llava)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs_zh.md#moe-llava) |
|         LLaVA-Phi         | 2024-01 |    arXiv     |        3B         |                             None                             | [![arXiv](https://img.shields.io/badge/Arxiv-2401.02330-b31b1b.svg?logo=arXiv)](https://arxiv.org/pdf/2401.02330) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/zhuyiche/llava-phi) |                             None                             | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs.md#llava-phi)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs_zh.md#llava-phi) |
|         TinyGPT-V         | 2023-12 |    arXiv     |        ---        | [TinyGPT-V](https://huggingface.co/spaces/llizhx/TinyGPT-V)  | [![arXiv](https://img.shields.io/badge/arXiv-2312.16862-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2312.16862) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/DLYuanGod/TinyGPT-V) | [TinyGPT-Vü§ó](https://huggingface.co/Tyrannosaurus/TinyGPT-V) | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs.md#tinygpt-v)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs_zh.md#tinygpt-v) |
|     MobileVLM Series      | 2023-12 |    arXiv     | 1.4B/1.7B/2.7B/7B |                         Invalid Now                          | [![arXiv](https://img.shields.io/badge/Arxiv-2312.16886-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2312.16886) <br />[![arXiv](https://img.shields.io/badge/Arxiv-2402.03766-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2402.03766) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/Meituan-AutoML/MobileVLM) |             [mtgv](https://huggingface.co/mtgv)ü§ó             | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs.md#mobilevlm)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs_zh.md#mobilevlm) |
| SCA | 2023-12 | arXiv | --- | [DEMO.md ](https://github.com/xk-huang/segment-caption-anything/blob/main/docs/DEMO.md) | [![arXiv](https://img.shields.io/badge/Arxiv-2312.00869-b31b1b.svg?logo=arXiv)](https://arxiv.org/pdf/2312.00869v2) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/xk-huang/segment-caption-anything) | [SCA](https://huggingface.co/xk-huang/segment-caption-anything-gpt2_large-pt_vg/tree/main)ü§ó | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs.md#sca)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs_zh.md#sca) |
| Florence-2 | 2023-11 | arXiv | 120M/345M/1.2B/3B | [Florence 2](https://huggingface.co/spaces/gokaygokay/Florence-2) | [![arXiv](https://img.shields.io/badge/Arxiv-2311.06242-b31b1b.svg?logo=arXiv)](https://arxiv.org/pdf/2311.06242) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/retkowsky/florence-2) | [Florence](https://huggingface.co/collections/microsoft/florence-6669f44df0d87d9c3bfb76de)ü§ó | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs.md#florence2)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs_zh.md#florence2) |
|        Cog Series         | 2023-11 |  CVPR 2024   |      17B/18B      | [CogVLM & CogAgent](https://huggingface.co/spaces/THUDM/CogVLM-CogAgent) | [![arXiv](https://img.shields.io/badge/arXiv-2311.03079-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2311.03079) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/THUDM/CogVLM) |           [THUDM ](https://huggingface.co/THUDM)ü§ó            | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs.md#cog-series)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs_zh.md#cog-series) |
|          PaLI-3           | 2023-10 |    arXiv     |        5B         |                             None                             | [![arXiv](https://img.shields.io/badge/arXiv-2310.09199-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2310.09199) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/google-research/big_vision) |       None([PaliGemma](#paligemma) is based on PaLI-3)       | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs.md#pali-3)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs_zh.md#pali-3) |
|            IMP            | 2024-05 |    arXiv     |        3B         |             [xmbot.net](https://xmbot.net/imp/)              | [![arXiv](https://img.shields.io/badge/arXiv-2405.12107-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2405.12107) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/MILVLG/imp) |    [imp-v1-3b ü§ó](https://huggingface.co/MILVLG/imp-v1-3b)    | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs.md#imp)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs_zh.md#imp) |
|      MiniGPT4 Series      | 2023-04 |    arXiv     |      7B/13B       |                         Invalid Now                          | [![arXiv](https://img.shields.io/badge/arXiv-2304.10592-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2304.10592) <br />[![arXiv](https://img.shields.io/badge/arXiv-2310.09478-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2310.09478) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/Vision-CAIR/MiniGPT-4) |     [Vision-CAIR ü§ó](https://huggingface.co/Vision-CAIR)      | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs.md#minigpt4-series)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs_zh.md#minigpt4-series) |
|     LLaVA-Phi-3-mini      | 2024-04 |     ---      |        ---        |                             None                             |                                                              | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/InternLM/xtuner) | [LLaVA-Phi-3-miniü§ó](https://huggingface.co/collections/xtuner/llava-phi-3-mini-662a5f7b9416630a1ad91102) | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs.md#llava-phi-3-mini)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs_zh.md#llava-phi-3-mini) |
|           Cobra           | 2024-03 |    arXiv     |       3.5B        |     [Cobra](https://huggingface.co/spaces/han1997/cobra)     | [![arXiv](https://img.shields.io/badge/arXiv-2403.14520-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2403.14520) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/h-zhao1997/cobra) | [Cobra Familyü§ó](https://huggingface.co/collections/han1997/cobra-6615c3242851ba108027105d) | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs.md#cobra)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_LVLMs_zh.md#cobra) |



## Quick Start ‚Äî‚Äî large model for SegmentationüèÅ

| Model |  Date   | Publication | Parameters | Demo |                            Paper                             |                            Github                            |                          CheckPoint                          |                           Details                            |
| :---: | :-----: | :---------: | :--------: | :--: | :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
| LISA  | 2023-08 |  CVPR 2024  |    13B     | ---  | [![arXiv](https://img.shields.io/badge/Arxiv-2308.00692-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2308.00692) | [![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/dvlab-research/LISA) | [![Hugging Face model](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-model-blue)](https://huggingface.co/xinlai/LISA-13B-llama2-v1) | [EN](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_VPLLM.md#lisa)/[ZH](https://github.com/NKU-MetautoAI/awesome-large-vision-language-models/blob/main/README_VPLLM_zh.md#lisa) |
|       |         |             |            |      |                                                              |                                                              |                                                              |                                                              |
|       |         |             |            |      |                                                              |                                                              |                                                              |                                                              |



## Other Relevant Summary PlatformsüèóÔ∏è

**this navigation page also links to other relevant summary platforms**. Explore the sections below to find the information you need:

- **Benchmarking Inference Speed of Large Language Models**üöÄ

[GPU-Benchmarks-on-LLM-Inference](https://github.com/XiongjieDai/GPU-Benchmarks-on-LLM-Inference) uses various NVIDIA GPUs and Apple Silicon devices to test models like LLaMA 3 with the llama.cpp tool, measuring performance by tokens generated per second. It covers NVIDIA 3000, 4000, and A100 series, as well as Apple's M1, M2, and M3 chips.

- **Comprehensive Analysis and Comparison of Large Language Models**üîç

The website [LifeArchitect.ai/models](https://lifearchitect.ai/models) provides a comprehensive analysis and comparison of large language models (LLMs) such as GPT-3, GPT-4, and PaLM, detailing their sizes, capabilities, and training data.

- **Reliable Measurement of Large Language Model Response Times**‚è±Ô∏è

[TheFastest.ai](https://thefastest.ai/) offers reliable performance measurements for popular large language models (LLMs) based on response times. It compares models across multiple data centers (e.g., US West, East, and Europe), focusing on metrics like Time to First Token (TTFT) and Tokens Per Second (TPS), with daily updated statistics.

- **Comprehensive Survey of Vision-Language Models**üìä

[VLM_survey](https://github.com/jingyi0000/VLM_survey) is a repository summarizing and surveying the latest vision-language models (VLMs), including links to relevant papers. It covers:

1. **Overview of Vision-Language Models**: Reviews VLM research in image classification, object detection, and semantic segmentation.
2. **Pre-training Methods**: Summarizes network architectures, pre-training objectives, and downstream tasks for VLMs.
3. **Transfer Learning Methods**: Discusses transfer learning strategies for VLMs in different tasks.
4. **Knowledge Distillation Methods**: Examines knowledge distillation techniques in tasks like object detection and semantic segmentation.

- **Latest Research, Datasets, and Evaluation Benchmarks in Multimodal Large Language Models**üìö

Check out the [repository](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models) for the **latest papers** on multimodal large language models, covering topics such as multimodal chain-of-thought, LLM-aided visual reasoning, foundation models, and multimodal reinforcement learning from human feedback (RLHF).

It also includes a variety of **datasets** for pre-training, alignment, multimodal instruction tuning, in-context learning, and evaluation, along with **benchmark tests** to assess the performance and capabilities of different multimodal models.

- **A lightweight library for evaluating language models from OpenAI**

OpenAI recently released a [practical library for LLMs](https://github.com/openai/simple-evals) aimed at ensuring the transparency of the accuracy data they publish for their models, such as GPT-4-turbo,ChatGPT4 and ChatGPT4o. This library includes benchmarks like MMLU, MATH, GPQA, DROP, MGSM, and HumanEval.

## Reference

    @misc{hu2024awesome,
      author       = {Bocheng Hu, Ge-Peng Ji, Deng-Ping Fan},
      title        = {An awesome list of large vision language models},
      howpublished = {\url{https://github.com/NKU-MetautoAI/awesome-large-vision-language-models}},
      year         = {2024}
    }

