<div align="center">
  <img src="./image/title.png" width="800" />
</div>
<div align="center">
 <strong>å…³äºè¿‘æœŸçš„<span style="color:red;">LLMs</span>çš„github Awesome ListğŸŒâœ¨</strong><br>
<strong>ä¸­æ–‡</strong> | <strong><a href="./README_LLM.md">EnglishğŸš€</a></strong><br>
<strong>LLMs</strong> | <strong><a href="./README_VLMs.md">VLMsğŸš€</a></strong>
</div>



## è¿‘æœŸLLMæ¦‚è§ˆ

<div align="center">
  <img src="./image/LLM2023.png"  width="800" />
</div>
<div align="center">
  <img src="./image/LLM2024.png"  width="800" />
</div>
*<em>å›¾ç‰‡æ¥æº: <a href="https://lifearchitect.ai/models">LifeArchitect.ai/models</a></em>*

## å¿«é€Ÿå¼€å§‹ğŸ

|    Model     |     Organization      |        Parameters        |                          CheckPoint                          |            Details            |
| :----------: | :-------------------: | :----------------------: | :----------------------------------------------------------: | :---------------------------: |
|   Llama 2    |         Meta          |        7B/13B/70B        | [Llama2 FamilyğŸ¤—](https://huggingface.co/collections/meta-llama/llama-2-family-661da1f90a9d678b6f55773b) |     [Hyperlink](#llama2)      |
|   Llama 3    |         Meta          |          8B/70B          | [Llama3 FamilyğŸ¤—](https://huggingface.co/collections/meta-llama/meta-llama-3-66214712577ca38149ebb2b6) |     [Hyperlink](#llama3)      |
|    Orca2     |       Microsoft       |          7B/13B          | [Orca FamilyğŸ¤—](https://huggingface.co/collections/microsoft/orca-65bbeef1980f5719cccc89a3) |      [Hyperlink](#orca2)      |
|     Qwen     |        Alibaba        | 0.5B/1.8B/4B/7B/14B/72B  |             [QwenğŸ¤—](https://huggingface.co/Qwen)             |         [Hyperlink](#qwen)         |
|   Qwen1.5    |        Alibaba        | 0.5B/1.8B/4B/7B/14B/72B  |           [Qwen1.5ğŸ¤—](https://huggingface.co/Qwen)            |      [Hyperlink](#qwen15)       |
|    Vicuna    |         LMSYS         |        7B/13B/33B        |           [VicunağŸ¤—](https://huggingface.co/lmsys)            |       [Hyperlink](#vicuna)       |
|     XGen     |      Salesforce       |            7B            | [xgen-7b-4k-baseğŸ¤—](https://huggingface.co/Salesforce/xgen-7b-4k-base) |         [Hyperlink](#xgen)         |
|    Falcon    |          UAE          |    1.3B/7.5B/40B/180B    | [Falcon FamilyğŸ¤—](https://huggingface.co/collections/tiiuae/falcon-64fb432660017eeec9837b5a) |       [Hyperlink](#falcon)       |
|     phi      |       Microsoft       |        1B/1.5B/2B        | [phi-1BğŸ¤—](https://huggingface.co/microsoft/phi-1)<br />[phi-1.5BğŸ¤—](https://huggingface.co/microsoft/phi-1_5)<br />[phi-2BğŸ¤—](https://huggingface.co/microsoft/phi-2) |          [Hyperlink](#phi)          |
|     phi3     |       Microsoft       |       3.8B/7B/14B        | [Phi-3 familyğŸ¤— **(only phi-3-mini is available now)**](https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3) |         [Hyperlink](#phi3)         |
|    Gemma     |        Google         |          2B/7B           | [Gemma FamilyğŸ¤—](https://huggingface.co/collections/google/gemma-release-65d5efbccdbb8c4202ec078b) |        [Hyperlink](#gemma)        |
|    Mamba     | Albert Gu and Tri Dao | 130M/370M/790M/1.4B/2.8B |     [state-spacesğŸ¤—](https://huggingface.co/state-spaces)     |        [Hyperlink](#mamba)        |
|    Pythia    |      EleutherAI       |         14Mï½12B         | [Pythia FamilyğŸ¤—](https://huggingface.co/collections/EleutherAI/pythia-scaling-suite-64fb5dfa8c21ebb3db7ad2e1) |       [Hyperlink](pythia)        |
|   Mistral    |      Mistral AI       |            7B            |         [MistralğŸ¤—](https://huggingface.co/mistralai)         |      [Hyperlink](#Mistral)      |
|      YI      |         01-ai         |        6B/9B/34B         | [Yi Family](https://huggingface.co/collections/01-ai/yi-2023-11-663f3f19119ff712e176720f) |           [Hyperlink](#yi)           |
|    YI-1.5    |         01-ai         |        6B/9B/34B         | [Yi-1.5 FamilyğŸ¤—](https://huggingface.co/collections/01-ai/yi-15-2024-05-663f3ecab5f815a3eaca7ca8) |       [Hyperlink](#yi-15)        |
|    Zephyr    |     Hugging Face      |            7B            |   [HuggingFaceH4ğŸ¤— ](https://huggingface.co/HuggingFaceH4)    |       [Hyperlink](#zephyr)       |
| StripedHyena |      Together AI      |            7B            | [StripedHyena FamilyğŸ¤—](https://huggingface.co/collections/togethercomputer/stripedhyena-65d8e6e77540dd1da932dbe1) | [Hyperlink](#stripedHyena) |
|  Persimmon   |     Adept AI Labs     |            8B            | [persimmon-8b-chatğŸ¤—](https://huggingface.co/adept/persimmon-8b-chat) |    [Hyperlink](#persimmon)    |



## æ¨¡å‹ç»†èŠ‚ğŸ“Š

### Llama2

[![arXiv](https://img.shields.io/badge/arXiv-2307.09288-b31b1b.svg)](https://arxiv.org/abs/2307.09288) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/meta-llama/llama)
[![Hugging Face model](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-models-blue)](https://huggingface.co/collections/meta-llama/llama-2-family-661da1f90a9d678b6f55773b)


Llama 2é¢„è®­ç»ƒæ¨¡å‹ç›¸è¾ƒäº Llama 1 æ¨¡å‹æœ‰æ˜¾è‘—æå‡ï¼Œå¢åŠ äº† 40% çš„è®­ç»ƒè¯å…ƒæ€»æ•°ï¼Œå¹¶é‡‡ç”¨äº†æ›´é•¿çš„ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆé«˜è¾¾ 4000 è¯å…ƒï¼‰ï¼ŒåŒæ—¶è¿˜åˆ©ç”¨åˆ†ç»„æŸ¥è¯¢æ³¨æ„åŠ›æœºåˆ¶ï¼Œæå¤§åŠ é€Ÿäº† 70B æ¨¡å‹çš„æ¨ç†é€Ÿåº¦ã€‚Llama 2-Chat ç³»åˆ—æ¨¡å‹é‡‡ç”¨äº†åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰æŠ€æœ¯ï¼Œä¸“é—¨é’ˆå¯¹å¯¹è¯åœºæ™¯è¿›è¡Œä¼˜åŒ–ã€‚åœ¨å¹¿æ³›çš„æœ‰ç”¨æ€§å’Œå®‰å…¨æ€§æµ‹è¯•åŸºå‡†ä¸­ï¼ŒLlama 2-Chat çš„è¡¨ç°è¶…è¿‡äº†å¤šæ•°ç°æœ‰å¼€æ”¾æ¨¡å‹ï¼Œå¹¶ä¸”åœ¨äººç±»è¯„ä¼°ä¸­æ˜¾ç¤ºå‡ºä¸ ChatGPT ç›¸åª²ç¾çš„æ€§èƒ½ã€‚

- **Date:** 2023-07
- **Pretrain Data Scale:** 2T
- **Language Support:** en
- **Parameter Size:** 7B/13B/70B



### Llama3

[![AI Blog](https://img.shields.io/badge/AI%20Blog-Meta%20AI-orange.svg)](https://ai.meta.com/blog/)
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/meta-llama/llama3)
[![Hugging Face model](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-models-blue)](https://huggingface.co/collections/meta-llama/meta-llama-3-66214712577ca38149ebb2b6)

ç›¸è¾ƒäº Llama 2ï¼ŒLlama 3 æœ€æ˜¾è‘—çš„å˜åŒ–åœ¨äºå¼•å…¥äº†ä¸€ä¸ªæ–°çš„ Tokenizerï¼Œå¹¶å°†è¯æ±‡è¡¨çš„è§„æ¨¡æ‰©å±•åˆ°äº† 128,256 ä¸ªè¯æ±‡ï¼ˆå…ˆå‰ç‰ˆæœ¬ä¸º 32,000 ä¸ª Tokenï¼‰ã€‚è¿™æ ·ä¸€ä¸ªæ›´åºå¤§çš„è¯æ±‡è¡¨å¯ä»¥æ›´æœ‰æ•ˆåœ°å¯¹æ–‡æœ¬è¿›è¡Œç¼–ç ï¼Œæ— è®ºæ˜¯è¾“å…¥è¿˜æ˜¯è¾“å‡ºï¼Œä¹Ÿå¯èƒ½å¢å¼ºæ¨¡å‹å¤„ç†å¤šè¯­è¨€çš„èƒ½åŠ›ã€‚ç„¶è€Œï¼Œè¿™ä¸€æ”¹å˜åŒæ—¶å¯¼è‡´äº†åµŒå…¥å±‚çš„è¾“å…¥å’Œè¾“å‡ºçŸ©é˜µçš„å°ºå¯¸å¢å¤§ï¼Œä»è€Œå¢åŠ äº†å°å‹æ¨¡å‹çš„å‚æ•°é‡ã€‚

- **Date:** 2024-04
- **Pretrain Data Scale:** 1.5T
- **Language Support:** en
- **Parameter Size:** 8B/70B



### Orca2
[![arXiv](https://img.shields.io/badge/arXiv-2311.11045-b31b1b.svg)](https://arxiv.org/pdf/2311.11045.pdf) 
[![Hugging Face collection](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-models-blue)](https://huggingface.co/collections/microsoft/orca-65bbeef1980f5719cccc89a3)


Orca 2 is a finetuned version of LLAMA-2. Orca 2â€™s training data is a synthetic dataset that was created to enhance the small modelâ€™s reasoning abilities. All synthetic training data was moderated using the Microsoft Azure content filters.

è®ºæ–‡ä¸­è¯¦ç»†ä»‹ç»äº†Orca æ˜¯å¦‚ä½•åœ¨è¾ƒå°æ¨¡å‹çš„æƒ…å†µä¸‹ï¼Œä¹Ÿèƒ½åª²ç¾ GPT 3.5 ç”šè‡³ GPT 4 çš„å¤§è¯­è¨€æ¨¡å‹ã€‚

- **Date:** 2023-11
- **Pretrain Data Scale:** same as LLAMA-2
- **Language Support:** en
- **Parameter Size:** 7B/13B



### Qwen

[![arXiv](https://img.shields.io/badge/arXiv-2309.16609-b31b1b.svg)](https://arxiv.org/abs/2309.16609) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/QwenLM/Qwen) 
[![Hugging Face model](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-models-blue)](https://huggingface.co/Qwen)

é€šè¿‡æŒ‡ä»¤å¾®è°ƒï¼ˆInstruction Fine-Tuningï¼‰å¯¹ç‰¹å®šä»»åŠ¡è¿›è¡Œä¼˜åŒ–ï¼Œæ¯”å¦‚ç¼–ç¨‹è¯­è¨€ç”Ÿæˆï¼ˆCodeQwenï¼‰ï¼Œé‡‡ç”¨äº†æ··åˆä¸“å®¶ï¼ˆMixture of Experts, MoEï¼‰å’Œç¨€ç–æ¿€æ´»æŠ€æœ¯.

- **Date:** 2023-08
- **Pretrain Data Scale:** 2.2T~3T(1.8B:2.2T;7B:2.4T;14B:3.0T)
- **Language Support:** en,zh
- **Parameter Size:** 0.5B/1.8B/4B/7B/14B/72B



### Qwen1.5

[![AI Blog](https://img.shields.io/badge/AI%20Blog-QWen%20AI-orange.svg)](https://qwen.readthedocs.io/en/latest/) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/QwenLM/Qwen1.5) 
[![Hugging Face model](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-models-blue)](https://huggingface.co/Qwen)

Qwen1.5çš„å„ä¸ªæ¨¡å‹åœ¨è®­ç»ƒä¸Šä½¿ç”¨äº†æ›´å¤šçš„Tokenï¼Œå¹¶é’ˆå¯¹ç‰¹å®šä»»åŠ¡å¦‚ä»£ç ç”Ÿæˆè¿›è¡Œäº†æŒ‡ä»¤å¾®è°ƒã€‚ä¾‹å¦‚ï¼ŒCodeQwen1.5ä¸“é—¨é’ˆå¯¹ç¼–ç¨‹ä»»åŠ¡è¿›è¡Œäº†ä¼˜åŒ–ï¼Œé¢„è®­ç»ƒäº†å¤§çº¦3ä¸‡äº¿ä¸ªä¸ä»£ç ç›¸å…³çš„æ•°æ®Tokenã€‚

- **Date:** 2023-02
- **Pretrain Data Scale:** 3T
- **Language Support:** en,zh
- **Parameter Size:** 0.5B/1.8B/4B/7B/14B/72B



### Vicuna

[![AI Blog](https://img.shields.io/badge/AI%20Blog-Vicuna%20AI-orange.svg)](https://lmsys.org/blog/2023-03-30-vicuna/) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/lm-sys/FastChat) 
[![Hugging Face model](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-models-blue)](https://huggingface.co/lmsys)

1. **å†…å­˜ä¼˜åŒ–**ï¼šä¸ºåº”å¯¹Vicunaåœ¨å¤„ç†é•¿ä¸Šä¸‹æ–‡æ—¶çš„éœ€æ±‚ï¼Œå…¶æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦ä»Alpacaçš„512å¢è‡³2048ï¼Œè¿™æ˜¾è‘—æé«˜äº†å¯¹GPUå†…å­˜çš„éœ€æ±‚ã€‚ä¸ºè§£å†³è¿™ä¸€é—®é¢˜ï¼Œç ”ç©¶äººå‘˜é‡‡ç”¨äº†æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆgradient checkpointingï¼‰ä¸FlashAttentionæŠ€æœ¯æ¥å‡è½»å†…å­˜å‹åŠ›ã€‚
2. **å¤šè½®å¯¹è¯**ï¼šé€šè¿‡è°ƒæ•´è®­ç»ƒæŸå¤±ä»¥é€‚åº”å¤šè½®å¯¹è¯çš„éœ€æ±‚ï¼Œè®­ç»ƒæŸå¤±çš„è®¡ç®—ä»…åŸºäºèŠå¤©æœºå™¨äººçš„è¾“å‡ºè¿›è¡Œã€‚
3. **é€šè¿‡Spotå®ä¾‹é™ä½æˆæœ¬**ï¼šæ•°æ®é›†è§„æ¨¡å¢å¤§40å€åŠåºåˆ—é•¿åº¦å¢åŠ 4å€ï¼Œå¯¹è®­ç»ƒæå‡ºäº†æ›´å¤§çš„æŒ‘æˆ˜ã€‚ä¸ºé™ä½æˆæœ¬ï¼Œç ”ç©¶äººå‘˜é€šè¿‡SkyPilotæ‰˜ç®¡çš„Spotå®ä¾‹ï¼Œåˆ©ç”¨æŠ¢å è‡ªåŠ¨æ¢å¤å’Œè‡ªåŠ¨åŒºåŸŸåˆ‡æ¢åŠŸèƒ½ï¼Œä½¿ç”¨æˆæœ¬æ›´ä½çš„Spotå®ä¾‹ã€‚è¿™ç§ç­–ç•¥å°†7Bæ¨¡å‹çš„è®­ç»ƒæˆæœ¬ä»500ç¾å…ƒé™è‡³çº¦140ç¾å…ƒï¼Œ13Bæ¨¡å‹çš„è®­ç»ƒæˆæœ¬ä»å¤§çº¦1000ç¾å…ƒé™è‡³300ç¾å…ƒã€‚

- **Date:** 2023-03
- **Pretrain Data Scale:** 1.4T
- **Language Support:** en,zh
- **Parameter Size:** 7B/13B/33B



### XGen

[![arXiv](https://img.shields.io/badge/arXiv-2309.03450-b31b1b.svg)](https://arxiv.org/abs/2309.03450) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/salesforce/xGen) 
[![Hugging Face model](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-models-blue)](https://huggingface.co/Salesforce/xgen-7b-4k-base)

XGen-7Bæ¨¡å‹åœ¨æ”¯æŒé•¿è¾¾8Kä»¤ç‰Œçš„è¾“å…¥ï¼Œé€šè¿‡ä½¿ç”¨æ ‡å‡†å¯†é›†æ³¨æ„åŠ›è¿›è¡Œè®­ç»ƒï¼Œä»¥åŠåœ¨é«˜è¾¾1.5Tä»¤ç‰Œçš„æƒ…å†µä¸‹è¿›è¡Œè®­ç»ƒï¼ŒåŒæ—¶åœ¨å…¬å…±é¢†åŸŸçš„æ•™å­¦æ•°æ®ä¸Šè¿›è¡Œå¾®è°ƒï¼Œå¯ä½œä¸ºä¸€ç§é€šç”¨æ¨¡å‹ï¼Œé€‚ç”¨äºæ ‡å‡†å¤§å°çš„GPUå’Œç§»åŠ¨è®¾å¤‡ã€‚

- **Date:** 2023-07
- **Pretrain Data Scale:** 1.37T
- **Language Support:** en
- **Parameter Size:** 7B



### Falcon

[![AI Blog](https://img.shields.io/badge/AI%20Blog-Falcon%20AI-orange.svg)](https://huggingface.co/blog/falcon-180b) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/falconry/falcon) 
[![Hugging Face model](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-models-blue)](https://huggingface.co/tiiuae)

å¤§é‡è®­ç»ƒæ•°æ®æ¥è‡ª [RefinedWeb](https://arxiv.org/abs/2306.01116) â€”â€” ä¸€ä¸ªæ–°çš„åŸºäº CommonCrawl çš„ç½‘ç»œæ•°æ®é›†ã€‚ä½¿ç”¨äº† [**å¤šæŸ¥è¯¢æ³¨æ„åŠ› (multiquery attention)**](https://arxiv.org/abs/1911.02150)ã€‚åŸå§‹å¤šå¤´ (head) æ³¨æ„åŠ›æ–¹æ¡ˆæ¯ä¸ªå¤´éƒ½åˆ†åˆ«æœ‰ä¸€ä¸ªæŸ¥è¯¢ (query) ã€é”® (key) ä»¥åŠå€¼ (value)ï¼Œè€Œå¤šæŸ¥è¯¢æ³¨æ„åŠ›æ–¹æ¡ˆæ”¹ä¸ºåœ¨æ‰€æœ‰å¤´ä¸Šå…±äº«åŒä¸€ä¸ªé”®å’Œå€¼ã€‚è¿™ä¸ªæŠ€å·§å¯¹é¢„è®­ç»ƒå½±å“ä¸å¤§ï¼Œä½†å®ƒæå¤§åœ° [æé«˜äº†æ¨ç†çš„å¯æ‰©å±•æ€§](https://arxiv.org/abs/2211.05102): äº‹å®ä¸Šï¼Œ **è¯¥æŠ€å·§å¤§å¤§å‡å°‘äº†è‡ªå›å½’è§£ç æœŸé—´ K,V ç¼“å­˜çš„å†…å­˜å ç”¨ï¼Œå°†å…¶å‡å°‘äº† 10-100 å€** (å…·ä½“æ•°å€¼å–å†³äºæ¨¡å‹æ¶æ„çš„é…ç½®)ï¼Œè¿™å¤§å¤§é™ä½äº†æ¨¡å‹æ¨ç†çš„å†…å­˜å¼€é”€ã€‚è€Œå†…å­˜å¼€é”€çš„å‡å°‘ä¸ºè§£é”æ–°çš„ä¼˜åŒ–å¸¦æ¥äº†å¯èƒ½ï¼Œå¦‚çœä¸‹æ¥çš„å†…å­˜å¯ä»¥ç”¨æ¥å­˜å‚¨å†å²å¯¹è¯ï¼Œä»è€Œä½¿å¾—æœ‰çŠ¶æ€æ¨ç†æˆä¸ºå¯èƒ½ã€‚

- **Date:** 2023-07
- **Pretrain Data Scale:** 2T
- **Language Support:** en,fr
- **Parameter Size:** 1.3B/7.5B/40B/180B



### Phi

[![AI Blog](https://img.shields.io/badge/AI%20Blog-Phi%20AI-orange.svg)](https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/microsoft/dstoolkit-phi2-finetune) 
[![Hugging Face model](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-models-blue)](https://huggingface.co/microsoft/phi-2)

**è®­ç»ƒæ•°æ®è´¨é‡ï¼š** åˆ©ç”¨â€œæ•™ç§‘ä¹¦è´¨é‡â€çš„æ•°æ®ï¼Œä¸“æ³¨äºæ—¨åœ¨ä¼ æˆå¸¸è¯†æ¨ç†å’Œå¸¸è¯†çš„åˆæˆæ•°æ®é›†ã€‚åŸ¹è®­è¯­æ–™åº“é€šè¿‡ç²¾å¿ƒæŒ‘é€‰çš„ç½‘ç»œæ•°æ®è¿›è¡Œæ‰©å……ï¼Œå¹¶æ ¹æ®æ•™è‚²ä»·å€¼å’Œå†…å®¹è´¨é‡è¿›è¡Œè¿‡æ»¤ã€‚ï¼ˆPhi-2 leverages â€œtextbook-qualityâ€ data, focusing on synthetic datasets designed to impart common sense reasoning and general knowledge. The training corpus is augmented with carefully selected web data, filtered based on educational value and content quality.ï¼‰

**åˆ›æ–°çš„ç¼©æ”¾æŠ€æœ¯ï¼š** å¾®è½¯åœ¨å¼€å‘ Phi-2 æ—¶ï¼Œé‡‡ç”¨äº†ä»å…¶å‰ä»£æ¨¡å‹ Phi-1.5 åˆ° Phi-2 çš„çŸ¥è¯†æ‰©å±•æŠ€æœ¯ã€‚ä»–ä»¬åˆ©ç”¨äº† Phi-1.5 æ¨¡å‹ä¸­å·²æœ‰çš„çŸ¥è¯†å’Œå­¦ä¹ æˆæœï¼Œå°†è¿™äº›çŸ¥è¯†è½¬ç§»åˆ°æ–°æ¨¡å‹ä¸­ï¼Œä»è€ŒåŠ é€Ÿäº†æ–°æ¨¡å‹è®­ç»ƒçš„æ”¶æ•›é€Ÿåº¦ã€‚ç®€å•æ¥è¯´ï¼Œå°±æ˜¯è®©æ–°æ¨¡å‹åœ¨å­¦ä¹ åˆæœŸå°±èƒ½ç«™åœ¨ä¸€ä¸ªæ›´é«˜çš„èµ·ç‚¹ä¸Šï¼Œå¿«é€Ÿè¾¾åˆ°é«˜æ€§èƒ½ã€‚è¿™ç§çŸ¥è¯†è½¬ç§»çš„æ–¹æ³•ä¸ä»…æé«˜äº†è®­ç»ƒæ•ˆç‡ï¼Œè¿˜æ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨å„ç§åŸºå‡†æµ‹è¯•ä¸­çš„å¾—åˆ†ã€‚

**ä¼˜åŒ–çš„Transformerç»“æ„**ï¼šPhi-2ç ”ç©¶äººå‘˜å¼•å…¥äº†è‡ªå®šä¹‰ä¼˜åŒ–ä»¥æœ€å¤§é™åº¦åœ°æé«˜æ•ˆç‡ã€‚

- **Date:** 2023-12
- **Pretrain Data Scale:** 1.4T
- **Language Support:** en
- **Parameter Size:** 1B/1.5B/2B



### Phi3

[![arXiv](https://img.shields.io/badge/arXiv-2404.14219-b31b1b.svg)](https://arxiv.org/abs/2404.14219) 
[![Hugging Face model](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-models-blue)](https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3)

é‡‡ç”¨äº†transformer decoderæ¶æ„ï¼Œå…¶é»˜è®¤çš„ä¸Šä¸‹æ–‡é•¿åº¦ä¸º**4K token**ã€‚å›¢é˜Ÿè¿˜é€šè¿‡LongRopeæŠ€æœ¯æ¨å‡ºäº†é•¿ä¸Šä¸‹æ–‡ç‰ˆæœ¬ï¼Œå°†ä¸Šä¸‹æ–‡é•¿åº¦æ‰©å±•åˆ°**128K token**ã€‚ç”±äºä½“ç§¯å°å·§ï¼Œphi-3-miniæ¨¡å‹å¯ä»¥è¢«é‡åŒ–ä¸º**4 bit**ï¼Œä½¿å…¶å†…å­˜å ç”¨ä»…çº¦ä¸º**1.8GB**ã€‚å›¢é˜Ÿé€šè¿‡åœ¨é…å¤‡A16ä»¿ç”ŸèŠ¯ç‰‡çš„iPhone 14ä¸Šéƒ¨ç½²phi-3-miniè¿›è¡Œäº†æµ‹è¯•ï¼Œè¯¥æ¨¡å‹èƒ½å¤Ÿåœ¨å®Œå…¨ç¦»çº¿çš„çŠ¶æ€ä¸‹åŸç”Ÿè¿è¡Œï¼Œå¹¶å®ç°äº†æ¯ç§’å¤„ç†è¶…è¿‡12ä¸ªtokensçš„é€Ÿåº¦ã€‚

è®­ç»ƒæ•°æ®é›†ä¹Ÿæ˜¯åˆ›æ–°ç‚¹ä¹‹ä¸€ï¼ŒåŒ…æ‹¬ç»è¿‡ä¸¥æ ¼è¿‡æ»¤çš„ç½‘ç»œæ•°æ®å’Œåˆæˆæ•°æ®ï¼Œè¿™äº›æ•°æ®ç»è¿‡ç²¾å¿ƒç­›é€‰å’Œä¼˜åŒ–ï¼Œä½¿ç ”ç©¶äººå‘˜èƒ½å¤Ÿæ˜¾è‘—å‡å°æ¨¡å‹çš„å¤§å°è€Œä¸å½±å“æ€§èƒ½ã€‚

- **Date:** 2024-04
- **Pretrain Data Scale:** 3.3Tï½4.8T
- **Language Support:** en
- **Parameter Size:** 3.8B/7B/14B



### Gemma

[![AI Blog](https://img.shields.io/badge/AI%20Blog-Phi%20AI-orange.svg)](https://storage.googleapis.com/deepmind-media/gemma/gemma-report.pdf) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/google-deepmind/gemma) 
[![Hugging Face model](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-models-blue)](https://huggingface.co/collections/google/gemma-release-65d5efbccdbb8c4202ec078b)

å¯åœ¨å„ç±»æ¶ˆè´¹çº§ç¡¬ä»¶ä¸Šè¿è¡Œï¼Œæ— éœ€æ•°æ®é‡åŒ–å¤„ç†ï¼Œæ‹¥æœ‰é«˜è¾¾ 8K tokens çš„å¤„ç†èƒ½åŠ›ï¼Œåœ¨ 7B å‚æ•°çº§åˆ«Gemma è¡¨ç°å‡ºè‰²ï¼Œæ¯”åŒå‚æ•°çº§åˆ«çš„Llama2æ€§èƒ½è¦å¥½ä¸€äº›ã€‚ä¸ Google Cloud é›†æˆï¼Œå¯ä»¥é€šè¿‡ Vertex AI æˆ– Google Kubernetes Engine (GKE) åœ¨ Google Cloud ä¸Šéƒ¨ç½²å’Œè®­ç»ƒ Gemmaã€‚

- **Date:** 2024-02
- **Pretrain Data Scale:** 2T
- **Language Support:** en
- **Parameter Size:** 2B/7B



### Mamba

[![arXiv](https://img.shields.io/badge/arXiv-2312.00752-b31b1b.svg)](https://arxiv.org/abs/2312.00752) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/state-spaces/mamba) 
[![Hugging Face model](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-models-blue)](https://huggingface.co/state-spaces)
- **Date:** 2023-12
- **Pretrain Data Scale:** 10B
- **Language Support:** en
- **Parameter Size:** 130M/370M/790M/1.4B/2.8B

Mamba 2.8B æ˜¯ä¸€ç§åŸºäºçŠ¶æ€ç©ºé—´æ¨¡å‹æ¶æ„çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œåœ¨å¤„ç†ä¿¡æ¯å¯†é›†å‹æ•°æ®ï¼ˆå¦‚è¯­è¨€å»ºæ¨¡ï¼‰æ–¹é¢å¯ä»¥å’Œä¼ ç»Ÿçš„ Transformer æ¨¡å‹ç«äº‰ã€‚

ä¸»è¦åˆ›æ–°ç‚¹å¦‚ä¸‹

1. **é€‰æ‹©æ€§çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMsï¼‰**ï¼šMamba é€šè¿‡åŸºäºè¾“å…¥å‚æ•°åŒ– SSM å‚æ•°å¼•å…¥äº†é€‰æ‹©æœºåˆ¶ã€‚è¿™ä½¿å¾—æ¨¡å‹å¯ä»¥æ ¹æ®å½“å‰ä»¤ç‰Œæ²¿åºåˆ—é•¿åº¦ç»´åº¦é€‰æ‹©æ€§åœ°ä¼ æ’­æˆ–é—å¿˜ä¿¡æ¯ï¼Œå¢å¼ºäº†å…¶èšç„¦ç›¸å…³ä¿¡æ¯åŒæ—¶ä¸¢å¼ƒæ— å…³æ•°æ®çš„èƒ½åŠ›ã€‚

2. **ç¡¬ä»¶æ„ŸçŸ¥å¹¶è¡Œç®—æ³•ï¼š** ä¸ºäº†å…‹æœé€‰æ‹©æ€§çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMsï¼‰å¸¦æ¥çš„è®¡ç®—å¤æ‚æ€§ï¼ŒMamba é‡‡ç”¨äº†ä¸€ç§ç¡¬ä»¶æ„ŸçŸ¥ç®—æ³•ï¼Œä½¿ç”¨æ‰«æè€Œéå·ç§¯æ¥è®¡ç®—æ¨¡å‹

   > æ‰«ææ“ä½œåœ¨é€’å½’è®¡ç®—ä¸­æ›´å¸¸è§ï¼Œå°¤å…¶æ˜¯åœ¨å¤„ç†éœ€è¦æ ¹æ®è¾“å…¥åŠ¨æ€è°ƒæ•´å‚æ•°çš„æ¨¡å‹æ—¶ï¼Œåœ¨ Mamba æ¨¡å‹ä¸­ï¼Œç”±äºå¼•å…¥äº†é€‰æ‹©æ€§æœºåˆ¶ï¼Œä½¿å¾—æ¨¡å‹çš„å‚æ•°å¯ä»¥æ ¹æ®è¾“å…¥åŠ¨æ€å˜åŒ–ï¼Œè¿™ç ´åäº†å·ç§¯çš„ä½¿ç”¨æ¡ä»¶ã€‚æ‰«ææ“ä½œæŒ‰ç…§åºåˆ—çš„é¡ºåºï¼Œä¸€æ­¥æ­¥åœ°è®¡ç®—åºåˆ—çš„çŠ¶æ€ï¼Œå…è®¸æ¯ä¸€æ­¥çš„è®¡ç®—éƒ½å¯ä»¥åŸºäºå½“å‰çš„è¾“å…¥å’Œå‰ä¸€çŠ¶æ€åŠ¨æ€è°ƒæ•´ã€‚

3. **é•¿ä¸Šä¸‹æ–‡å¤„ç†**ï¼šå¯ä»¥è¾¾åˆ°100ä¸‡åºåˆ—é•¿åº¦ï¼Œåœ¨éŸ³é¢‘å¤„ç†å’ŒåŸºå› ç»„å­¦æ–¹é¢æ€§èƒ½è‰¯å¥½





### Pythia
[![arXiv](https://img.shields.io/badge/arXiv-2304.01373-b31b1b.svg)](https://arxiv.org/abs/2304.01373) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/EleutherAI/pythia) 
[![Hugging Face model](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-models-blue)](https://huggingface.co/collections/EleutherAI/pythia-scaling-suite-64fb5dfa8c21ebb3db7ad2e1)
- **Date:** 2023-04
- **Pretrain Data Scale:** 10B
- **Language Support:** en
- **Parameter Size:** 130M/370M/790M/1.4B/2.8B


Pythia *Scaling Suite*æ˜¯ä¸ºä¿ƒè¿›å¯è§£é‡Šæ€§ç ”ç©¶è€Œå¼€å‘çš„æ¨¡å‹é›†åˆï¼Œis a suite of 16 LLMs all trained on public data seen in the exact same order and ranging in size from 70M to 12B parameters.

> å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¥—ä»¶ï¼Œæ˜¯ä¸€ç³»åˆ—ç”¨äºç§‘å­¦ç ”ç©¶çš„è¯­è¨€æ¨¡å‹çš„é›†åˆã€‚è¿™äº›æ¨¡å‹åœ¨è®¾è®¡å’Œå®ç°æ—¶æ³¨é‡ä¸€è‡´æ€§å’Œå¯é‡ç°æ€§ï¼Œç›®çš„æ˜¯è®©ç ”ç©¶è€…èƒ½å¤Ÿæ·±å…¥åˆ†æå’Œç†è§£å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è®­ç»ƒå’Œæ‰©å±•è¿‡ç¨‹ä¸­çš„è¡¨ç°å’Œå˜åŒ–ã€‚

Pythia contains two sets of eight models of sizes 70M, 160M, 410M, 1B, 1.4B, 2.8B, 6.9B, and 12B. For each size, there are two models: one trained on the Pile, and one trained on the Pile after the dataset has been globally deduplicated. All 8 model sizes are trained on the exact same data, in the exact same order. 

> Pile æ˜¯ä¸€ä¸ªå¤§å‹çš„ã€å¼€æºçš„è‹±æ–‡æ–‡æœ¬æ•°æ®é›†ï¼Œä¸“ä¸ºè®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹è€Œè®¾è®¡ã€‚å®ƒç”± 22 ä¸ªä¸åŒçš„ã€é«˜è´¨é‡çš„å­æ•°æ®é›†ç»„æˆï¼Œè¿™äº›å­æ•°æ®é›†åŒ…æ‹¬äº†ä»ä¹¦ç±ã€å­¦æœ¯è®ºæ–‡ã€æ³•å¾‹æ–‡çŒ®ã€åœ¨çº¿é—®ç­”ï¼Œåˆ°ç¼–ç¨‹ä»£ç å’Œç”µå½±å­—å¹•ç­‰å¤šç§ç±»å‹çš„æ–‡æœ¬ã€‚è¢«å¹¿æ³›ç”¨äºè®­ç»ƒåŒ…æ‹¬è‡ªå›å½’å˜æ¢å™¨åœ¨å†…çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼Œè¯¦æƒ…ï¼š[click here](https://pile.eleuther.ai/)ã€‚

Pythiaå¥—ä»¶æ˜¯å”¯ä¸€ä¸€ä¸ªæ»¡è¶³ä»¥ä¸‹ä¸‰ä¸ªå…³é”®ç‰¹æ€§çš„å…¬å¼€å‘å¸ƒçš„LLMå¥—ä»¶ï¼š

1. æ¨¡å‹è¦†ç›–äº†å¤šä¸ªæ•°é‡çº§çš„æ¨¡å‹è§„æ¨¡ã€‚
2. æ‰€æœ‰æ¨¡å‹éƒ½æŒ‰ç…§ç›¸åŒçš„é¡ºåºåœ¨ç›¸åŒçš„æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒã€‚
3. æ•°æ®å’Œä¸­é—´æ£€æŸ¥ç‚¹å¯ä¾›å…¬å¼€ç ”ç©¶ä½¿ç”¨ã€‚

ä½œè€…è¿˜è¿›è¡Œäº†ä¸‰ä¸ªè¯­è¨€å»ºæ¨¡ç ”ç©¶çš„æ¡ˆä¾‹ç ”ç©¶

1. **æ•°æ®åè§å¦‚ä½•å½±å“å­¦ä¹ è¡Œä¸º**ï¼šç ”ç©¶è¡¨æ˜ï¼Œé€šè¿‡å¯¹è¯­è¨€æ¨¡å‹çš„é€‚å½“å¹²é¢„ï¼Œå¯ä»¥å‘ç°æ•°æ®ä¸­ä»£è¯çš„å‡ºç°é¢‘ç‡ä¼šå½±å“æ¨¡å‹çš„å­¦ä¹ åå·®ã€‚ç ”ç©¶ä¹Ÿæå‡ºä¸€ç§å¯æ§çš„æ–¹æ³•æ¥åˆ†æå’Œå‡è½»æ¨¡å‹çš„åå·®é—®é¢˜ã€‚
2. **è®­ç»ƒé¡ºåºæ˜¯å¦å½±å“è®°å¿†**ï¼šç ”ç©¶è€…å‘ç°ï¼Œæ³Šæ¾æ¨¡å‹èƒ½å¤Ÿå¾ˆå¥½åœ°é€‚é…æ•°æ®ï¼Œè¿™è¯´æ˜è®­ç»ƒé¡ºåºå¯¹äºè®°å¿†çš„å½±å“è¾ƒå°ã€‚è¯¥æ¨¡å‹è¡¨æ˜ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹çš„å¼€å§‹æˆ–ç»“æŸé˜¶æ®µï¼Œè®°å¿†åºåˆ—å¹¶ä¸ä¼šæ›´å¯†é›†åœ°å‡ºç°ï¼Œè€Œæ˜¯åœ¨å„ä¸ªæ£€æŸ¥ç‚¹ä¹‹é—´ï¼Œå¯ä»¥è§‚å¯Ÿåˆ°å¤§è‡´ç›¸åŒæ•°é‡çš„è®°å¿†åºåˆ—åˆ†å¸ƒã€‚
3. **é¢„è®­ç»ƒæœ¯è¯­é¢‘ç‡æ˜¯å¦å½±å“æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­çš„ä»»åŠ¡æ€§èƒ½**ï¼šè¿™ç§ç›¸å…³æ€§åœ¨è¾ƒå¤§çš„æ¨¡å‹ä¸­è¡¨ç°å¾—æ›´ä¸ºæ˜æ˜¾ã€‚è¾ƒå°çš„æ¨¡å‹å³ä¾¿åœ¨è®­ç»ƒçš„åæœŸé˜¶æ®µä¹Ÿå¾ˆéš¾åœ¨è¿™äº›ä»»åŠ¡ä¸Šå–å¾—å‡†ç¡®çš„ç»“æœï¼Œè¡¨æ˜è¿™äº›æ¨¡å‹æ— è®ºè®­ç»ƒæ•°æ®ä¸­ç›¸å…³ä¿¡æ¯çš„é¢‘ç‡å¦‚ä½•ï¼Œéƒ½æ— æ³•æˆåŠŸå­¦ä¹ è¿™äº›ä»»åŠ¡ã€‚





### Mistral
[![arXiv](https://img.shields.io/badge/arXiv-2310.06825-b31b1b.svg)](https://arxiv.org/abs/2310.06825) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/mistralai/mistral-common) 
[![Hugging Face model](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-models-blue)](https://huggingface.co/mistralai)

- **Date:** 2023-09
- **Pretrain Data Scale:** 8T
- **Language Support:** en
- **Parameter Size:** 7B

Mistral 7B è¶…è¶Šäº†ä»¥å‰æœ€å¥½çš„ 130 äº¿å‚æ•°æ¨¡å‹ï¼ˆLlama 2ï¼‰åœ¨æ‰€æœ‰è¯„æµ‹åŸºå‡†ä¸Šçš„è¡¨ç°ï¼Œå¹¶ä¸”åœ¨æ¨ç†ã€æ•°å­¦å’Œä»£ç ç”Ÿæˆæ–¹é¢è¶…è¿‡äº†æœ€å¥½çš„ 340 äº¿å‚æ•°æ¨¡å‹ï¼ˆLlama 1ï¼‰ï¼Œåˆ©ç”¨åˆ†ç»„æŸ¥è¯¢æ³¨æ„åŠ›ï¼ˆGrouped-query Attention, GQAï¼‰å’Œæ»‘åŠ¨çª—å£æ³¨æ„åŠ›ï¼ˆSliding Window Attention, SWAï¼‰ã€‚GQA æ˜¾è‘—æé«˜äº†æ¨ç†é€Ÿåº¦ï¼Œå‡å°‘äº†è§£ç æ—¶çš„å†…å­˜éœ€æ±‚ã€‚SWA èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°å¤„ç†æ›´é•¿çš„åºåˆ—ï¼Œä»è€Œé™ä½è®¡ç®—æˆæœ¬ã€‚

Mistral-7B is a decoder-only Transformer with the following architectural choices:

- Sliding Window Attention - Trained with 8k context length and fixed cache size, with a theoretical attention span of 128K tokens
- GQA (Grouped Query Attention) - allowing faster inference and lower cache size.
- Byte-fallback BPE tokenizer - ensures that characters are never mapped to out of vocabulary tokens.



### YI
[![arXiv](https://img.shields.io/badge/arXiv-2403.04652-b31b1b.svg)](https://arxiv.org/abs/2403.04652) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/01-ai/Yi) 
[![Hugging Face collections](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-collections-blue)](https://huggingface.co/collections/01-ai/yi-2023-11-663f3f19119ff712e176720f)

- **Date:** 2023-11
- **Pretrain Data Scale:**0. 8Tï½3T
- **Language Support:** Multiple
- **Parameter Size:** 6B/9B/34B

Yiç³»åˆ—åŒ…æ‹¬6Bã€9Bå’Œ34Bå‚æ•°è§„æ¨¡çš„åŸºç¡€æ¨¡å‹ï¼Œæ¯ä¸ªæ¨¡å‹çš„é»˜è®¤ä¸Šä¸‹æ–‡çª—å£ä¸º4Kï¼Œå¹¶åœ¨æ¨ç†æ—¶å¯ä»¥æ‰©å±•åˆ°32Kã€‚

æ ¸å¿ƒäº®ç‚¹æœ‰ä»¥ä¸‹å‡ æ–¹é¢

1. **é«˜è´¨é‡æ•°æ®é¢„å¤„ç†**ï¼šYiç³»åˆ—æ¨¡å‹ä½¿ç”¨äº†ä¸¥æ ¼çš„æ¸…æ´—ç®¡é“æ¥ç¡®ä¿é«˜è´¨é‡çš„è®­ç»ƒæ•°æ®ã€‚è¿™åŒ…æ‹¬ä½¿ç”¨å¯å‘å¼è§„åˆ™å’Œå­¦ä¹ è¿‡æ»¤å™¨æ¥å»é™¤ä½è´¨é‡å’Œä¸é€‚å½“çš„å†…å®¹ï¼Œç¡®ä¿æ•°æ®é›†çš„çº¯å‡€åº¦å’Œç›¸å…³æ€§ã€‚
2. **æ”¹è¿›çš„æ³¨æ„åŠ›æœºåˆ¶**ï¼šYiæ¨¡å‹é‡‡ç”¨äº†æ”¹è¿›çš„Grouped-Query Attentionï¼ˆGQAï¼‰æœºåˆ¶ï¼Œè¿™å¤§å¤§å‡å°‘äº†è®­ç»ƒå’Œæ¨ç†çš„æˆæœ¬ï¼Œä¸ä¼ ç»Ÿçš„å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ç›¸æ¯”å…·æœ‰æ›´é«˜çš„æ•ˆç‡ã€‚
3. **å¤šæ¨¡æ€æ”¯æŒ**ï¼šYiç³»åˆ—è¿˜åŒ…æ‹¬å¤šæ¨¡æ€æ¨¡å‹ï¼ˆYi-VLï¼‰ï¼Œè¿™äº›æ¨¡å‹èƒ½å¤Ÿå¤„ç†æ–‡æœ¬å’Œå›¾åƒè¾“å…¥ï¼Œè¿›è¡Œå¤šè½®å¯¹è¯å’Œè§†è§‰é—®ç­”ã€‚
4. **å¯¹ä¸­æ–‡æ”¯æŒæ›´å¥½**ï¼šå¯¹æ ‡chatGPT4åœ¨CMMLUã€E-Evalã€Gaokao ä¸‰ä¸ªä¸»è¦çš„ä¸­æ–‡æŒ‡æ ‡ä¸ŠYi-34Bè¡¨ç°å¾—å¾ˆå¥½ã€‚

> Grouped-Query Attention (GQA) æœºåˆ¶çš„åŸç†ï¼šä¼ ç»Ÿçš„å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ä¸­ï¼Œæ¯ä¸ªæ³¨æ„åŠ›å¤´éƒ½æœ‰è‡ªå·±ç‹¬ç«‹çš„æŸ¥è¯¢ï¼ˆQï¼‰ã€é”®ï¼ˆKï¼‰å’Œå€¼ï¼ˆVï¼‰å‘é‡ã€‚åœ¨GQAä¸­ï¼ŒæŸ¥è¯¢å¤´è¢«åˆ†æˆè‹¥å¹²ç»„ï¼Œæ¯ç»„å…±äº«ä¸€ä¸ªé”®ï¼ˆKï¼‰å’Œä¸€ä¸ªå€¼ï¼ˆVï¼‰å‘é‡ã€‚å…·ä½“æ¥è¯´ï¼Œå¦‚æœä¸€ä¸ªæ³¨æ„åŠ›å±‚æœ‰`H`ä¸ªæŸ¥è¯¢å¤´ï¼Œè¿™äº›æŸ¥è¯¢å¤´è¢«åˆ†æˆ`G`ç»„ï¼ˆ`G < H`ï¼‰ï¼Œæ¯ç»„å…±äº«ç›¸åŒçš„Kå’ŒVå‘é‡ã€‚
>
> åœ¨GQAæœºåˆ¶ä¸‹ï¼Œé”®å’Œå€¼å‘é‡çš„è®¡ç®—æ¬¡æ•°å‡å°‘ï¼Œå› ä¸ºåŒä¸€ç»„å†…çš„å¤šä¸ªæŸ¥è¯¢å¤´å…±äº«ç›¸åŒçš„Kå’ŒVã€‚è¿™å‡å°‘äº†çŸ©é˜µä¹˜æ³•çš„æ¬¡æ•°ï¼Œä»è€Œé™ä½äº†è®¡ç®—å¤æ‚åº¦ã€‚



### YI-1.5
[![arXiv](https://img.shields.io/badge/arXiv-2403.04652-b31b1b.svg)](https://arxiv.org/abs/2403.04652) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/01-ai/Yi-1.5) 
[![Hugging Face collections](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-collections-blue)](https://huggingface.co/collections/01-ai/yi-15-2024-05-663f3ecab5f815a3eaca7ca8)

- **Date:** 2023-05
- **Pretrain Data Scale:** 3.6T
- **Language Support:** Multiple
- **Parameter Size:** 6B/9B/34B

Yi-1.5æ¨¡å‹é¢„è®­ç»ƒåœ¨5000äº¿é«˜è´¨é‡è¯­æ–™åº“ä¸Šï¼Œå¹¶åœ¨300ä¸‡å¤šæ ·åŒ–æ ·æœ¬ä¸Šè¿›è¡Œäº†å¾®è°ƒã€‚è¿™ç§å¤§è§„æ¨¡çš„æ•°æ®è®­ç»ƒä½¿å¾—æ¨¡å‹åœ¨ç¼–ç¨‹ã€æ•°å­¦ã€æ¨ç†å’ŒæŒ‡ä»¤éµå¾ªä»»åŠ¡ä¸Šçš„æ€§èƒ½æ›´å¼ºã€‚åŒ…æ‹¬34Bã€9Bå’Œ6Bå‚æ•°æ¨¡å‹ï¼Œæ¯ç§æ¨¡å‹æ”¯æŒçš„ä¸Šä¸‹æ–‡é•¿åº¦åˆ†åˆ«ä¸º4Kã€16Kå’Œ32Kã€‚

åœ¨Yi-1.5ç³»åˆ—ä¸­ç‰¹åˆ«æ˜¯9Bæ¨¡å‹ï¼Œé‡‡ç”¨äº†**åæœŸå±‚çš„å¤åˆ¶æ–¹æ³•**ä»¥æé«˜æ¨¡å‹æ€§èƒ½ï¼ŒåŒæ—¶ä¿æŒé«˜æ•ˆçš„è®­ç»ƒã€‚ä¸ä¼ ç»Ÿçš„æ¨¡å‹æ‰©å±•æ–¹æ³•ç›¸æ¯”ï¼Œè¿™ç§æ–¹æ³•èƒ½æ›´å¥½åœ°ä¿æŒæ€§èƒ½ï¼Œå‡å°‘æŸå¤±ã€‚

æœ€å¤§çš„ Yi 1.5. 34B åœ¨åŸºå‡†æµ‹è¯•ä¸­å‡ ä¹ä¸ Meta Llama 3 70B ç›¸å½“ã€‚

> Yi-34B-200Kåœ¨â€œNeedle-in-a-Haystackâ€æµ‹è¯•ä¸­çš„è¡¨ç°ä»89.3%æé«˜åˆ°99.8%







### Zephyr
[![arXiv](https://img.shields.io/badge/arXiv-2310.16944-b31b1b.svg)](https://arxiv.org/abs/2310.16944) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/huggingface/alignment-handbook) 
- **Date:** 2023-05
- **Pretrain Data Scale:** According to LLM
- **Language Support:** en
- **Parameter Size:** 7B

Zephyr ç³»åˆ—å¤§è¯­è¨€æ¨¡å‹é‡‡ç”¨äº†å¤šæ ·çš„åå¥½ä¼˜åŒ–æŠ€æœ¯ï¼Œä½¿å…¶æ›´ç¬¦åˆç‰¹å®šçš„ç”¨æˆ·åå¥½æˆ–ä»»åŠ¡éœ€æ±‚ã€‚è¿™ä¸ªç³»åˆ—å…±æœ‰ä¸‰ä¸ªæ¨¡å‹ï¼Œæ¯ä¸ªæ¨¡å‹ä½¿ç”¨äº†ä¸åŒçš„åå¥½ä¼˜åŒ–ç®—æ³•å’Œåº•åº§LLMã€‚

> åå¥½ä¼˜åŒ–æŠ€æœ¯å¯ä»¥ç¡®ä¿ç”Ÿæˆçš„è¾“å‡ºæ›´ç¬¦åˆæœŸæœ›ï¼Œ**å‡å°‘ä¸è‰¯è¾“å‡º**ï¼Œå¯ä»¥æå¤§åœ°å¢å¼ºæ¨¡å‹çš„å®šåˆ¶åŒ–èƒ½åŠ›ã€‚



#### Zephyr-7B

[![Hugging Face collections](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-collections-blue)](https://huggingface.co/collections/HuggingFaceH4/zephyr-7b-6538c6d6d5ddd1cbb1744a66
)

Zephyr-7B-Î² æ˜¯Zephyr ç³»åˆ—åˆ—ä¸­çš„ç¬¬ä¸€ä¸ªæ¨¡å‹ï¼Œæ˜¯åŸºäº [Mistralai/Mistral-7B-v0.1](https://link.zhihu.com/?target=https%3A//huggingface.co/mistralai/Mistral-7B-v0.1) å¾®è°ƒè€Œæ¥çš„ï¼Œä½¿ç”¨çš„æ˜¯**ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰**ç®—æ³•

æ­¤å¤–è¯¥æ¨¡å‹åˆ©ç”¨çŸ¥è¯†è’¸é¦æŠ€æœ¯ï¼Œå³ç”¨è¾ƒå°çš„â€œå­¦ç”Ÿâ€æ¨¡å‹å­¦ä¹ å’Œå¤åˆ¶è¾ƒå¤§â€œæ•™å¸ˆâ€æ¨¡å‹çš„æ€§èƒ½ã€‚è¿™ä½¿å¾—Zephyr-7Båœ¨ä¿ç•™è¾ƒå¤§æ¨¡å‹èƒ½åŠ›çš„åŒæ—¶ï¼Œå…·æœ‰æ›´é«˜çš„è®¡ç®—æ•ˆç‡ï¼Œå¹¶ä¸”æ›´å®¹æ˜“éƒ¨ç½²åœ¨è®¡ç®—èµ„æºæœ‰é™çš„è®¾å¤‡ä¸Šã€‚

ä½¿ç”¨çš„æ•°æ®é›†æ˜¯UltraChatå’ŒUltraFeedbackæ•°æ®é›†

- UltraChatæ˜¯ç”±ChatGPTç”Ÿæˆçš„åˆæˆå¯¹è¯æ•°æ®é›†
- UltraFeedbackåŒ…å«äº†å„ç§æç¤ºå’Œå“åº”ï¼Œå¹¶ç”±GPT-4è¿›è¡Œäº†æ³¨é‡Š

>ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDirect Preference Optimization, DPOï¼‰é€šè¿‡ç›´æ¥æœ€å¤§åŒ–æ¨¡å‹ç”Ÿæˆçš„é¦–é€‰å“åº”çš„æ¦‚ç‡æ¥è¿›è¡Œåå¥½å¯¹é½ã€‚DPOç®—æ³•é€šè¿‡ç›´æ¥ä¼˜åŒ–æ¨¡å‹ç”Ÿæˆçš„é¦–é€‰å“åº”çš„æ¦‚ç‡ï¼Œè€Œä¸éœ€è¦å‚è€ƒæ¨¡å‹ï¼Œç®€åŒ–äº†è®­ç»ƒè¿‡ç¨‹ã€‚



#### Zephyr ORPO
[![Hugging Face collections](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-collections-blue)](https://huggingface.co/collections/HuggingFaceH4/zephyr-orpo-6617eba2c5c0e2cc3c151524)

Zephyr-ORPO-141B-A35b-v0.1æ˜¯ä¸€ä¸ªå…·æœ‰ 141B æ€»å‚æ•°å’Œ 39B æœ‰æ•ˆå‚æ•°çš„ä¸“å®¶æ··åˆ ï¼ˆMoEï¼‰ æ¨¡å‹ï¼Œæ˜¯åœ¨[Mixtral-8x22B-v0.1](https://huggingface.co/mistral-community/Mixtral-8x22B-v0.1)çš„åŸºç¡€ä¸Šå¾®è°ƒçš„ã€‚é‡‡ç”¨[Odds Ratio Preference Optimization (ORPO)](https://huggingface.co/papers/2403.07691)ç®—æ³•è¿›è¡Œåå¥½ä¼˜åŒ–ï¼ŒORPO ä¸éœ€è¦ SFT æ­¥éª¤å³å¯å®ç°é«˜æ€§èƒ½ï¼Œå› æ­¤è®¡ç®—æ•ˆç‡æ¯” DPO å’Œ PPO ç­‰æ–¹æ³•é«˜å¾—å¤šã€‚

ORPOæ¨¡å‹é€šè¿‡åŠ¨æ€æƒ©ç½šæœºåˆ¶è¿˜å¯ä»¥æœ‰æ•ˆåœ°å‡å°‘äº†ä¸è‰¯å“åº”çš„ç”Ÿæˆï¼Œç¡®ä¿è¾“å‡ºå†…å®¹çš„é«˜è´¨é‡å’Œé€‚ç”¨æ€§ã€‚

> **Odds Ratio Preference Optimization (ORPO)** ç®—æ³•é€šè¿‡è®¡ç®—é¦–é€‰å“åº”å’Œéé¦–é€‰å“åº”çš„èµ”ç‡æ¯”è¿›è¡Œä¼˜åŒ–ï¼Œç¡®ä¿æ¨¡å‹æ›´å€¾å‘äºç”Ÿæˆé¦–é€‰å“åº”ã€‚



#### Zephyr-7B Gemma
[![Hugging Face collections](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-collections-blue)](https://huggingface.co/collections/HuggingFaceH4/zephyr-7b-gemma-65e1fd82d26b426e3e63d956)

æ˜¯åœ¨HuggingFaceH4/deita-10k-v0-sft æ•°æ®é›†ä¸Š [google/gemma-7b](https://huggingface.co/google/gemma-7b) çš„å¾®è°ƒç‰ˆæœ¬ï¼Œä½¿ç”¨çš„ä¹Ÿæ˜¯DPOçš„åå¥½ä¼˜åŒ–ç®—æ³•ã€‚



### StripedHyena
[![AI Blog](https://img.shields.io/badge/AI%20Blog-Phi%20AI-orange.svg)](https://www.together.ai/blog/stripedhyena-7b) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/togethercomputer/stripedhyena) 

[![Hugging Face collections](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-collections-blue)](https://huggingface.co/collections/togethercomputer/stripedhyena-65d8e6e77540dd1da932dbe1)

-  2023-12
- **Pretrain Data Scale:** 2T
- **Language Support:** Multiple
- **Parameter Size:** 7B

è¯¥æ¨¡å‹ç³»åˆ—åŒ…æ‹¬ StripedHyena-Hessian-7B å’Œ StripedHyena-Nous-7B ä¸¤ä¸ªä¸»è¦å˜ç§ã€‚[å‰è€…](https://huggingface.co/togethercomputer/StripedHyena-Hessian-7B)ä¸ºåŸºç¡€æ¨¡å‹[åè€…](https://huggingface.co/togethercomputer/StripedHyena-Nous-7B)ä¸ºèŠå¤©æ¨¡å‹

StripedHyena é‡‡ç”¨äº†ä¸€ç§æ··åˆæ¶æ„ï¼Œç»“åˆäº†é—¨æ§å·ç§¯ï¼ˆgated convolutionsï¼‰å’Œåˆ†ç»„æŸ¥è¯¢æ³¨æ„åŠ›æœºåˆ¶ï¼ˆgrouped-query attentionï¼‰ã€‚è¯¥æ¨¡å‹çš„æ ¸å¿ƒç»„ä»¶æ˜¯çŠ¶æ€ç©ºé—´æ¨¡å‹ï¼ˆSSMï¼‰å±‚ï¼Œä¼ ç»Ÿä¸Šç”¨äºå»ºæ¨¡å¤æ‚åºåˆ—å’Œæ—¶é—´åºåˆ—æ•°æ®ã€‚SSM å±‚èƒ½å¤Ÿæ›´é«˜æ•ˆåœ°å¤„ç†é•¿åºåˆ—ä»»åŠ¡ï¼Œå‡å°‘è®¡ç®—èµ„æºéœ€æ±‚ï¼Œç›¸è¾ƒäºç»å…¸çš„ Transformerï¼Œåœ¨é•¿åºåˆ—è®­ç»ƒä¸­é€Ÿåº¦æ›´å¿«ã€‚

StripedHyena è®­ç»ƒåºåˆ—é•¿åº¦å¯è¾¾ 32kï¼Œèƒ½å¤Ÿå¤„ç†æ›´é•¿çš„æç¤º



### Persimmon
[![AI Blog](https://img.shields.io/badge/AI%20Blog-Phi%20AI-orange.svg)](https://www.adept.ai/blog/persimmon-8b) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/persimmon-ai-labs/adept-inference) 
[![Hugging Face model](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-models-blue)](https://huggingface.co/adept/persimmon-8b-chat)

- **Date:** 2023-09
- **Pretrain Data Scale:**  0.737T
- **Language Support:** en
- **Parameter Size:** 8B

Persimmon-8B æ”¯æŒ 16K çš„ä¸Šä¸‹æ–‡é•¿åº¦ï¼Œæ˜¯ LLaMA2 çš„å››å€ï¼ŒGPT-3 çš„å…«å€

é‡‡ç”¨äº†ä¸€äº›æ¶æ„ä¼˜åŒ–ï¼ŒåŒ…æ‹¬å¹³æ–¹ ReLU æ¿€æ´»å‡½æ•°å’Œæ—‹è½¬ä½ç½®ç¼–ç ï¼ˆrotary positional encodingsï¼‰ã€‚

æ¨¡å‹çš„è¾“å…¥å’Œè¾“å‡ºåµŒå…¥è¿›è¡Œäº†åˆ†ç¦»ä¼˜åŒ–ï¼Œé¿å…äº†å¤§åµŒå…¥å±‚æ¢¯åº¦çš„å…¨é‡å‡å°‘ï¼Œä»è€Œæå‡äº†è®­ç»ƒæ•ˆç‡ã€‚







## æ¨¡å‹è¯„ä¼°å¹³å°

### OpenLLM Leaderboard by Hugging Face[[Leaderboard]](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)

Hugging Faceçš„OpenLLMæ’è¡Œæ¦œæ˜¯ä¸€ä¸ªæ—¨åœ¨è¿½è¸ªã€è¯„çº§å’Œè¯„ä¼°å¼€æºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å’ŒèŠå¤©æœºå™¨äººçš„å¹³å°ã€‚è¿™ä¸ªæ’è¡Œæ¦œæä¾›äº†ä¸€ä¸ªé›†ä¸­çš„å¹³å°ã€‚

[Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard) is actually just a wrapper running the open-source benchmarking library [Eleuther AI LM Evaluation Harness](https://github.com/EleutherAI/lm-evaluation-harness) created by the [EleutherAI non-profit AI research lab](https://www.eleuther.ai/) famous for creating [The Pile](https://pile.eleuther.ai/) and training [GPT-J](https://huggingface.co/EleutherAI/gpt-j-6b), [GPT-Neo-X 20B](https://huggingface.co/EleutherAI/gpt-neox-20b), and [Pythia](https://github.com/EleutherAI/pythia). A team with serious credentials in the AI space!ï¼ˆCitation from Hugging Face blogï¼‰



### Chatbot Arena by LMSYS and SkyLab[[Chatbot Arena]](https://arena.lmsys.org/)

Chatbot Arenaçš„ä¸»è¦åŠŸèƒ½ä»‹ç»ï¼š

1. **æ¨¡å‹å¯¹æˆ˜ï¼ˆArena Battleï¼‰**ï¼šåœ¨Chatbot Arenaä¸­ï¼Œç”¨æˆ·å¯ä»¥é€‰æ‹©ä¸¤ä¸ªä¸åŒçš„åŒ¿åæ¨¡å‹ï¼ˆå¦‚ChatGPTã€Claudeã€Llamaç­‰ï¼‰ï¼Œå¹¶å°†å®ƒä»¬è¿›è¡Œå¯¹æ¯”ã€‚åœ¨ä¸€ä¸ªå®‰å…¨çš„æ¯”èµ›ç¯å¢ƒä¸­ï¼Œç”¨æˆ·å¯ä»¥æé—®å¹¶è¯„ä¼°ä¸¤ä¸ªæ¨¡å‹çš„å›ç­”ï¼Œé€šè¿‡æŠ•ç¥¨å†³å®šå“ªä¸ªæ¨¡å‹è¡¨ç°æ›´å‡ºè‰²ã€‚è¿™ä¸€æ¯”è¾ƒè¿‡ç¨‹å¯ä»¥å¤šè½®è¿›è¡Œï¼Œç›´åˆ°ç¡®å®šæœ€ç»ˆçš„èƒœåˆ©è€…ã€‚ä¸ºäº†ä¿è¯æ¯”èµ›çš„å…¬å¹³æ€§ï¼Œå¦‚æœæŸè½®å¯¹è¯æš´éœ²äº†æ¨¡å‹çš„å…·ä½“èº«ä»½ï¼Œè¯¥è½®çš„æŠ•ç¥¨ç»“æœå°†è¢«æ’é™¤ã€‚
2. **å®æ—¶èŠå¤©ï¼ˆDirect Chatï¼‰**ï¼šChatbot Arenaæä¾›äº†ä¸€ä¸ªå®æ—¶èŠå¤©åŠŸèƒ½ï¼Œå…è®¸ç”¨æˆ·ç›´æ¥ä¸é€‰å®šçš„æ¨¡å‹è¿›è¡Œå¯¹è¯ã€‚æ— è®ºç”¨æˆ·é€‰æ‹©çš„æ˜¯æ–‡æœ¬è¿˜æ˜¯è§†è§‰èŠå¤©æ¨¡å¼ï¼Œéƒ½èƒ½å³æ—¶æ¥æ”¶åˆ°æ¨¡å‹çš„åé¦ˆã€‚
3. **æ’è¡Œæ¦œï¼ˆLeaderboardï¼‰**ï¼šChatbot Arenaé€šè¿‡åˆ†æè¶…è¿‡300,000ä¸ªäººç±»ç”¨æˆ·çš„æŠ•ç¥¨ç»“æœï¼Œé‡‡ç”¨åŸºäºEloç³»ç»Ÿçš„æ–¹æ³•æ¥è¯„ä¼°å„ä¸ªLLMçš„æ’åã€‚è¿™è®©ç”¨æˆ·èƒ½å¤Ÿç›´è§‚åœ°äº†è§£å“ªäº›æ¨¡å‹å½“å‰å¤„äºé¢†å…ˆåœ°ä½ï¼Œè½»æ¾è¯†åˆ«å‡ºLLMé¢†åŸŸçš„ä½¼ä½¼è€…ã€‚



## åŸºå‡†æµ‹è¯•

### ARC (AI2 Reasoning Challenge)

[![Paper with Code](https://img.shields.io/badge/Paper%20with%20Code-arc%20challenge-blue.svg)](https://paperswithcode.com/sota/common-sense-reasoning-on-arc-challenge)
[![Paper with Code](https://img.shields.io/badge/Paper%20with%20Code-arc%20easy-blue.svg)](https://paperswithcode.com/sota/common-sense-reasoning-on-arc-easy)
[![arXiv](https://img.shields.io/badge/arXiv-2305.18354-b31b1b.svg)](https://arxiv.org/pdf/2305.18354) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/fchollet/ARC) 

ARCï¼ˆAbstraction and Reasoning Corpusï¼‰åŸºå‡†æ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹æ€§èƒ½çš„æŒ‘æˆ˜æ€§æ¡†æ¶ï¼Œç‰¹åˆ«æ˜¯åœ¨æ‰§è¡Œéœ€è¦æŠ½è±¡å’Œæ¨ç†ä»»åŠ¡çš„èƒ½åŠ›æ–¹é¢ã€‚è¿™ä¸ªåŸºå‡†æµ‹è¯•æ˜¯æ¨åŠ¨AIæ¨¡å‹è¶…è¶Šå½“å‰è®¸å¤šåŸºå‡†ä¸­å¸¸è§çš„æ ‡å‡†æ¨¡å¼è¯†åˆ«ä»»åŠ¡çš„ä¸€éƒ¨åˆ†ã€‚

##### ARCçš„ä¸»è¦ç‰¹ç‚¹

- **ä»»åŠ¡è®¾è®¡**ï¼šARCä¸­çš„ä»»åŠ¡è®¾è®¡å¯¹äººç±»æ¥è¯´å¾ˆç®€å•ï¼Œä½†å¯¹AIæ¥è¯´å´å¾ˆæœ‰æŒ‘æˆ˜æ€§ã€‚æ¯ä¸ªä»»åŠ¡åŒ…æ‹¬ä¸€ä¸ªè¾“å…¥å’Œä¸€ä¸ªæ­£ç¡®çš„è¾“å‡ºï¼Œç›®æ ‡æ˜¯é€šè¿‡è¾¨åˆ«åº•å±‚æ¨¡å¼æˆ–è§„åˆ™ï¼Œä»è¾“å…¥ä¸­é¢„æµ‹è¾“å‡ºã€‚ä»»åŠ¡æ¶µç›–å„ç§è®¤çŸ¥åŠŸèƒ½ï¼ŒåŒ…æ‹¬æ¨¡å¼è¯†åˆ«ã€ç©ºé—´æ¨ç†å’Œé€»è¾‘æ¨ç†ã€‚
- **æ•°æ®é›†**ï¼šARCæ•°æ®é›†æ˜¯å…¬å¼€çš„ï¼ŒåŒ…æ‹¬è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œå…¶ä¸­æµ‹è¯•é›†åŒ…å«å®Œå…¨æ–°é¢–çš„ä»»åŠ¡ï¼Œéœ€è¦è¶…è¶Šè®­ç»ƒæ•°æ®è¿›è¡Œæ³›åŒ–ã€‚è¿™ç§è®¾ç½®æ—¨åœ¨æ¨¡æ‹Ÿç°å®ä¸–ç•Œçš„å­¦ä¹ åœºæ™¯ï¼Œåœ¨è¿™äº›åœºæ™¯ä¸­å¹¶éæ€»èƒ½ç›´æ¥è·å¾—ç­”æ¡ˆï¼Œå¿…é¡»åº”ç”¨æ¨ç†ã€‚
- **è¯„ä¼°**ï¼šåœ¨ARCä¸­å–å¾—æˆåŠŸéœ€è¦å¼€å‘èƒ½å¤ŸçœŸæ­£ç†è§£å’Œæ“ä½œæŠ½è±¡æ¦‚å¿µçš„æ¨¡å‹ï¼Œè¿™ä½¿å…¶æˆä¸ºæµ‹è¯•AIæ¨ç†èƒ½åŠ›çš„ä¸¥æ ¼æ ‡å‡†ï¼Œè€Œä¸ä»…ä»…æ˜¯å…¶æ•°æ®å¤„ç†èƒ½åŠ›çš„æµ‹è¯•ã€‚



### HellaSwag

[![Paper with Code](https://img.shields.io/badge/Paper%20with%20Code-hellaswag-blue.svg)](https://paperswithcode.com/sota/sentence-completion-on-hellaswag)
[![arXiv](https://img.shields.io/badge/arXiv-1905.07830-b31b1b.svg)](https://arxiv.org/abs/1905.07830) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/rowanz/hellaswag) 

**HellaSwag**æ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°è¯­è¨€æ¨¡å‹åœ¨å¸¸è¯†è‡ªç„¶è¯­è¨€æ¨ç†æ–¹é¢è¡¨ç°çš„åŸºå‡†ã€‚å®ƒç‰¹åˆ«æµ‹è¯•æ¨¡å‹é¢„æµ‹æ—¥å¸¸æ´»åŠ¨ç®€å•æè¿°çš„å»¶ç»­éƒ¨åˆ†çš„èƒ½åŠ›ï¼Œè¿™äº›æè¿°å¯¹äººç±»æ¥è¯´æ˜¾è€Œæ˜“è§ï¼Œä½†å¯¹ç®—æ³•æ¥è¯´å¯èƒ½å…·æœ‰æŒ‘æˆ˜æ€§ã€‚è¯¥åŸºå‡†åŒ…å«å¤§é‡é€‰æ‹©é¢˜ï¼Œæ¯é¢˜æä¾›ä¸€ä¸ªåœºæ™¯å’Œå››ä¸ªå¯èƒ½çš„å»¶ç»­ï¼Œæ¨¡å‹å¿…é¡»ä»ä¸­é€‰æ‹©æœ€åˆé€‚çš„ä¸€ä¸ªã€‚

HellaSwagä¸­çš„é—®é¢˜ä¸»è¦æ¥è‡ªä¸¤ä¸ªé¢†åŸŸï¼šActivityNetå’ŒWikiHowï¼Œä¸°å¯Œäº†æ•°æ®é›†çš„å®é™…ç›¸å…³æ€§å’Œå¤šæ ·æ€§ã€‚æ­£ç¡®ç­”æ¡ˆæè¿°äº†å®é™…çš„ä¸‹ä¸€ä¸ªäº‹ä»¶ï¼Œè€Œå…¶ä»–ä¸‰ä¸ªé”™è¯¯é€‰é¡¹æ˜¯å¯¹æŠ—æ€§ç”Ÿæˆå¹¶ç»äººå·¥éªŒè¯ï¼Œæ—¨åœ¨è¯¯å¯¼æ¨¡å‹ä½†ä¸è¯¯å¯¼äººç±»ã€‚

HellaSwagçš„æ„å»ºåŒ…æ‹¬ä¸€ç§â€œå¯¹æŠ—æ€§è¿‡æ»¤â€æŠ€æœ¯ï¼Œä¸€ç³»åˆ—åˆ¤åˆ«å™¨åå¤é€‰æ‹©æœºå™¨ç”Ÿæˆçš„é”™è¯¯ç­”æ¡ˆï¼Œè¿™äº›ç­”æ¡ˆèƒ½å¤Ÿæœ‰æ•ˆåœ°æ¬ºéª—æ¨¡å‹ã€‚è¿™ç§æ–¹æ³•åœ¨æŒ‘æˆ˜æ¨¡å‹è¯†åˆ«ç°å®åœºæ™¯æ–¹é¢å·²è¢«è¯æ˜æœ‰æ•ˆï¼Œå¹¶ä¸”çªå‡ºäº†å³ä½¿æ˜¯æœ€å…ˆè¿›æ¨¡å‹çš„å±€é™æ€§ã€‚



### MMLU (Massive Multitask Language Understanding)

[![Paper with Code](https://img.shields.io/badge/Paper%20with%20Code-MMLU-blue.svg)](https://paperswithcode.com/sota/multi-task-language-understanding-on-mmlu?tag_filter=183)
[![arXiv](https://img.shields.io/badge/arXiv-2009.03300-b31b1b.svg)](https://arxiv.org/abs/2009.03300) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/hendrycks/test) 

è¿™æ˜¯ä¸€ä¸ªå¹¿æ³›è€Œå¤šæ ·çš„åŸºå‡†ï¼Œç”¨äºè¯„ä¼°æ¨¡å‹åœ¨ä»äººæ–‡å­¦ç§‘åˆ°ç§‘å­¦ç­‰å¹¿æ³›ä¸»é¢˜ä¸Šçš„ç†è§£èƒ½åŠ›ã€‚å®ƒæ—¨åœ¨æµ‹è¯•æ¨¡å‹åœ¨å„ç§ä¸»é¢˜ä¸Šçš„ä¸€èˆ¬çŸ¥è¯†å’Œç†è§£èƒ½åŠ›ã€‚

> æ³¨æ„ï¼šMMLUçš„è¯„ä¼°åŒ…å«ä¸‰ç§å½¢å¼ï¼Œåˆ†åˆ«æ˜¯MMLU (HELM)ã€MMLU (Harness)å’ŒMMLU (Original)ã€‚æ›¾ç»ï¼Œåœ¨Hugging Faceçš„OpenLLMæ’è¡Œæ¦œä¸Šï¼Œ[**LLaMA model ğŸ¦™**](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/)è¢«çˆ†å‡ºMMLUè¯„ä¼°ç»“æœæ˜æ˜¾ä½äº[å·²å‘è¡¨çš„ LLaMa è®ºæ–‡](https://arxiv.org/abs/2302.13971)ä¸­çš„æ•°å­—ã€‚æœ€ç»ˆ[Blog](https://huggingface.co/blog/open-llm-leaderboard-mmlu)ä¸Šçš„å£°æ˜å°†è¿™ä¸ªç°è±¡å½’ç»“ä¸ºç”¨äºæµ‹è¯•çš„MMLU benchmarkçš„ç»†èŠ‚ä¸åŒå¯¼è‡´äº†ç»“æœä¸åŒï¼Œè¯¦æƒ…å¯å‚è§[Blog](https://huggingface.co/blog/open-llm-leaderboard-mmlu)



### TruthfulQA

[![Paper with Code](https://img.shields.io/badge/Paper%20with%20Code-truthfulqa-blue.svg)](https://paperswithcode.com/sota/question-answering-on-truthfulqa)
[![arXiv](https://img.shields.io/badge/arXiv-2109.07958-b31b1b.svg)](https://arxiv.org/abs/2109.07958) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/sylinrl/TruthfulQA) 

è¯¥åŸºå‡†è¯„ä¼°æ¨¡å‹æä¾›çœŸå®ç­”æ¡ˆçš„èƒ½åŠ›ã€‚å®ƒé€šè¿‡æµ‹è¯•æ¨¡å‹å¦‚ä½•å¤„ç†å¯èƒ½é€šå¸¸ä¼šå¯¼è‡´ä¸çœŸå®æˆ–è¯¯å¯¼æ€§ç­”æ¡ˆçš„é—®é¢˜æ¥å‡å°‘é”™è¯¯ä¿¡æ¯çš„ä¼ æ’­ã€‚

**TruthfulQA**æ˜¯ä¸€ä¸ªè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ç”ŸæˆçœŸå®ç­”æ¡ˆèƒ½åŠ›çš„åŸºå‡†ã€‚å®ƒåŒ…å«38ä¸ªç±»åˆ«ä¸­çš„817ä¸ªé—®é¢˜ï¼ŒåŒ…æ‹¬å¥åº·ã€æ³•å¾‹ã€é‡‘èå’Œæ”¿æ²»ç­‰é¢†åŸŸã€‚é—®é¢˜æ—¨åœ¨è€ƒå¯Ÿæ¨¡å‹å¤„ç†äººç±»å¯èƒ½å› è¯¯è§£æˆ–é”™è¯¯ä¿¡å¿µè€Œå›ç­”é”™è¯¯çš„åœºæ™¯çš„èƒ½åŠ›ã€‚TruthfulQAçš„ä¸»è¦ç›®æ ‡æ˜¯è¡¡é‡æ¨¡å‹ç”ŸæˆçœŸå®å“åº”çš„å‡†ç¡®æ€§ã€‚åŸºå‡†ä½¿ç”¨å„ç§ä»»åŠ¡å’Œæ¨¡å¼ï¼ŒåŒ…æ‹¬å•é€‰å’Œå¤šé€‰é¢˜ä»¥åŠç”Ÿæˆä»»åŠ¡ï¼Œä»¥è¯„ä¼°æ¨¡å‹è¯†åˆ«å’Œç”ŸæˆçœŸå®ç­”æ¡ˆçš„èƒ½åŠ›ã€‚

##### ä»»åŠ¡å’Œè¯„ä¼°æ–¹æ³•

TruthfulQAåŒ…æ‹¬ä¸¤ä¸ªä¸»è¦ä»»åŠ¡ï¼š

1. **ç”Ÿæˆä»»åŠ¡**ï¼šæ¨¡å‹æ¥æ”¶ä¸€ä¸ªé—®é¢˜å¹¶ç”Ÿæˆä¸€åˆ°ä¸¤å¥è¯çš„ç­”æ¡ˆã€‚æ­¤ä»»åŠ¡çš„ä¸»è¦æŒ‡æ ‡æ˜¯æ¨¡å‹ç­”æ¡ˆçš„æ•´ä½“çœŸå®æ€§ï¼Œè¯„ä¼°æ ‡å‡†æ˜¯æè¿°ç°å®ä¸–ç•Œä¸­çš„å­—é¢çœŸå®æƒ…å†µã€‚æ¬¡è¦æŒ‡æ ‡åŒ…æ‹¬ä¿¡æ¯é‡ï¼Œé€šè¿‡è¯„ä¼°æ¨¡å‹æä¾›æœ‰æ„ä¹‰çš„ä¿¡æ¯è€Œä¸æ˜¯æ¨¡æ£±ä¸¤å¯çš„å“åº”ã€‚
2. **å¤šé€‰ä»»åŠ¡**ï¼šæ­¤ä»»åŠ¡æœ‰ä¸¤ç§å½¢å¼ï¼š
   - **MC1ï¼ˆå•ä¸€çœŸå®ï¼‰**ï¼šæ¨¡å‹æ¥æ”¶ä¸€ä¸ªé—®é¢˜å’Œè‹¥å¹²ç­”æ¡ˆé€‰é¡¹ï¼Œå¿…é¡»é€‰æ‹©å”¯ä¸€æ­£ç¡®çš„ç­”æ¡ˆã€‚
   - **MC2ï¼ˆå¤šé‡çœŸå®ï¼‰**ï¼šæ¨¡å‹æ¥æ”¶å¤šä¸ªçœŸå®å’Œè™šå‡çš„å‚è€ƒç­”æ¡ˆï¼Œå¿…é¡»è¯†åˆ«æ‰€æœ‰æ­£ç¡®ç­”æ¡ˆã€‚

##### é‡è¦ç‚¹

- **å¯¹æŠ—æ€§**ï¼šTruthfulQAä¸­çš„é—®é¢˜æ˜¯å¯¹æŠ—æ€§è®¾è®¡çš„ï¼Œæµ‹è¯•æ¨¡å‹ç”ŸæˆçœŸå®ç­”æ¡ˆçš„æ½œåœ¨å¼±ç‚¹ã€‚è¿™åŒ…æ‹¬è®¾è®¡åˆ©ç”¨å¸¸è§è¯¯è§£çš„é—®é¢˜ï¼Œæˆ–è€…ç”±äºæ¨¡å‹è®­ç»ƒæ•°æ®çš„åå·®å¯èƒ½ä¼šé”™è¯¯å›ç­”çš„é—®é¢˜ã€‚
- **éªŒè¯å’ŒåŸºå‡†**ï¼šè¯¥åŸºå‡†åŒ…æ‹¬éªŒè¯æœºåˆ¶ï¼Œå¤–éƒ¨ç ”ç©¶äººå‘˜è¯„ä¼°å‚è€ƒç­”æ¡ˆçš„çœŸå®æ€§å’Œå‡†ç¡®æ€§ï¼Œç¡®ä¿åŸºå‡†è¯„ä¼°çš„ç¨³å¥æ€§ã€‚



### Winogrande

[![Paper with Code](https://img.shields.io/badge/Paper%20with%20Code-Winogrande-blue.svg)](https://paperswithcode.com/sota/common-sense-reasoning-on-winogrande)
[![arXiv](https://img.shields.io/badge/arXiv-1907.10641-b31b1b.svg)](https://arxiv.org/pdf/1907.10641) 
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/allenai/winogrande) 

WINOGRANDEæ˜¯ä¸€ä¸ªåŸºäºWinograd Schema Challengeï¼ˆWSCï¼‰çš„è¯­è¨€ç†è§£åŸºå‡†ï¼Œæ—¨åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹åœ¨è§£å†³éœ€è¦å¸¸è¯†å’Œæ¨ç†èƒ½åŠ›çš„ä»£è¯è§£æé—®é¢˜ä¸Šçš„è¡¨ç°ã€‚é€šè¿‡æä¾›æ¯”åŸå§‹WSCæ›´å¤§å’Œæ›´å…·æŒ‘æˆ˜æ€§çš„æ•°æ®é›†ï¼ŒWINOGRANDEæ›´é€‚åˆè¯„ä¼°ç°ä»£äººå·¥æ™ºèƒ½è¯­è¨€æ¨¡å‹çš„èƒ½åŠ›ã€‚

ç”±è‰¾ä¼¦äººå·¥æ™ºèƒ½ç ”ç©¶æ‰€å¼€å‘ï¼ŒWINOGRANDEåŸºå‡†çš„ç›®çš„æ˜¯é€šè¿‡ä»£è¯è§£æä»»åŠ¡æµ‹è¯•æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚è¿™äº›ä»»åŠ¡é€šå¸¸æ¶‰åŠä¸€ä¸ªå¸¦æœ‰ä»£è¯å’Œå¤šä¸ªæ½œåœ¨æŒ‡ä»£çš„å¥å­ï¼Œæ¨¡å‹éœ€è¦ç¡®å®šä»£è¯çš„æ­£ç¡®æŒ‡ä»£ã€‚ä¾‹å¦‚ï¼š

```less
Sentence: The elephant put the apple there because it was ______.
Options: A) empty B) heavy
Correct Answer: A) empty

Sentence: The trophy doesnâ€™t fit into the suitcase because it is too small.â€œItâ€ refers ______.
Options: A) the trophy B) the suitcase
Correct Answer: B) the suitcase
```

è¿™ç§ç±»å‹çš„é—®é¢˜è¦æ±‚æ¨¡å‹ä¸ä»…ç†è§£è¯­è¨€çš„å­—é¢æ„æ€ï¼Œè¿˜éœ€è¦æ¨ç†å‡ºä¸Šä¸‹æ–‡ä¸­çš„éšå«å…³ç³»ã€‚	

### GSM8K (Grade School Math 8K)

[![Paper with Code](https://img.shields.io/badge/Paper%20with%20Code-GSM8K-blue.svg)](https://paperswithcode.com/dataset/gsm8k)
[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/openai/grade-school-math) 

GSM8Kï¼ˆGrade School Math 8Kï¼‰æ•°æ®é›†ç”±OpenAIå¼€å‘ï¼Œæ—¨åœ¨è¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹è§£å†³å°å­¦æ°´å¹³æ•°å­¦é—®é¢˜çš„èƒ½åŠ›ã€‚è¯¥åŸºå‡†åŒ…å«8500ä¸ªé«˜è´¨é‡ã€è¯­è¨€å¤šæ ·çš„æ•°å­¦æ–‡å­—é—®é¢˜ï¼Œéœ€è¦è¿›è¡ŒåŸºæœ¬çš„ç®—æœ¯è¿ç®—å¦‚åŠ æ³•ã€å‡æ³•ã€ä¹˜æ³•å’Œé™¤æ³•ã€‚è¿™äº›é—®é¢˜é€šå¸¸éœ€è¦ä¸¤åˆ°å…«æ­¥è§£å†³ã€‚æ•°æ®é›†åˆ†ä¸º7500ä¸ªè®­ç»ƒé—®é¢˜å’Œ1000ä¸ªæµ‹è¯•é—®é¢˜ï¼Œæ—¨åœ¨æµ‹è¯•æ¨¡å‹åœ¨å¤šæ­¥éª¤æ•°å­¦æ¨ç†ä¸­çš„èƒ½åŠ›ã€‚GSM8Kå¯¹äºè¯„ä¼°æ¨¡å‹å¤„ç†æ¶‰åŠé¡ºåºé€»è¾‘å’Œè®¡ç®—æ­¥éª¤çš„é—®é¢˜éå¸¸æœ‰ç”¨ã€‚
